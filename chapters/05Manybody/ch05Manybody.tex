\chapter{Quantum Monte Carlo}

\section{Modeling Diffusion}

Like any phenomena involving a density function, or distribution, Quantum Mechanics can be modeled by diffusion. In Quantum Mechanics, the distribution is given by $|\p|^2$, the Wave function squared. The diffusing elements of interest are the particles making up our system. The idea is to have an ensemble of \textit{Random Walkers} in which each walker represents a position is space (and time for time-dependent studies). Averaging values over the paths of the ensemble will yield average values corresponding to the probability distribution governing the movement of individual walkers. 

Such random movement is referred to as a \textit{Brownian motion}, named after the British Botanist R. Brown, originating from his experiments on plant pollen dispersed in water. \textit{Markov chains} are a subtype of Brownian motion, where a walkers next move is independent of previous moves. This is the stochastic process in which Quantum Monte Carlo is described.

The purpose of this section is to motivate the use of diffusion theory in Quantum Mechanics, and to derive the sampling rules needed in order to model Quantum Mechanical distributions by diffusion of random walkers correctly. I will be using natural units, that is $\hbar$, $m_e$, etc. are all set to unity, in order to simplify the expressions.

\subsection{Stating the \schrodinger as a Diffusion Problem}

Consider the time-dependent \schrodinger for an abstract state $\phi(x, t)$ with an arbitrary energy shift $E'$

\begin{equation}
 -\frac{\partial \phi(x, t)}{i\partial t} = (\OP{H} - E')\phi(x, t).
\end{equation}

Expanding $\phi(\vec r, t)$ in the eigenstates of $\OP{H}$ yield the following solution (given a time-independent Hamiltonian):

\begin{eqnarray}
 \phi(x, t) &=& \sum_{k=0}^{\infty} C_k\Phi_k(x)e^{-i(E_k - E')t} \\
 C_k &=& \braket{\Phi_k(x)}{\phi(x, t=0)}
\label{eq:realSchrod}
 \end{eqnarray}


The real form of this equation is obtained through a Wick rotation in time ($it \rightarrow \tau$), which basically means that the time-evolution operation is substituted by a \textit{projection operation}. To illustrate this, look at the solution of the real equation with $E'$ chosen to be the ground state energy of $\OP{H}$

\begin{eqnarray}
 \phi(x, \tau) &=& \sum_{k=0}^{\infty} C_k\Phi_k(x)e^{-(E_k - E_0)\tau} \\
                    &=& C_0\Phi_0(x) + \sum_{k=1}^{\infty} C_k\Phi_k(x)e^{-\delta E_k\tau},
\end{eqnarray}

where $\delta E_k = E_k - E_0 > 0$ for $k \ge 1$. Observe that as $\tau$ increase, the excited states of $\OP{H}$ will be exponentially dampened, hence the name projection operation. Note however, that no real-time solutions can be achieved by solving this equation; only in the limit $\tau\rightarrow\infty$ will the solution match that of the \schrodinger.

% The solution to this equation comes in term of a \textit{Green's Function}, a transition probability. 

Considering two sequential time steps $\tau$, $\tau + \delta\tau$, we can write the solution of Eq.~(\ref{eq:realSchrod}) as following

\begin{equation*}
 \ket{\phi(\tau + \delta\tau)} = e^{-(\OP{H} - E_0)\delta\tau}\ket{\phi(\tau)}.
\end{equation*}

Taking the inner product with $\bra{x}$ on both sides and inserting a complete set of states $\ket{y}$ on the left hand side yields

\begin{eqnarray*}
 \phi(x, \tau + \delta\tau) &=& \int \bra{x}e^{-(\OP{H} - E_0)\delta\tau}\ket{y}\phi(y, \tau)dy \\
			     &\equiv& \int G(x, y; \delta\tau)\phi(y, \tau)dy
\end{eqnarray*}

where the \textit{Green's Function}, $G(x, y; \delta\tau)$ serves as a transition probability. This is the path integral formalism of Quantum Mechanics, where a final state is obtained by integrating through all possible paths of all the particles in the system, but I will not go into details about it here. More information about this can be found in \cite{leinaas}. A more detailed derivation of the Green's Function are given in \cite{abInitioMC}.

This is still not a practical way of solving the equations. In finding the Green's function we might as well find the solution directly. However, what we can do, is make the time steps very small and split the Hamiltonian into the kinetic, $\OP{T}$ and the potential part, $\OP{V}$:

\begin{eqnarray}
 \bra{x}e^{-(\OP{H} - E_0)\delta\tau}\ket{y} &=& \bra{x}e^{-(\OP{T} + \OP{V} - E_0)\delta\tau}\ket{y} \nonumber \\
                                             &\approx& \bra{x}e^{-\OP{T}\delta\tau}e^{-(\OP{V} - E_0)\delta\tau}\ket{y}
\end{eqnarray}

This is known as the \textit{short time approximation}. The gain by doing this is that we split the Green's Function into two well known processes. The first which represents a diffusion process

\begin{equation}
 G_{diff} = e^{\frac{1}{2}\nabla^2\delta\tau}
\label{eq:GDiff}
\end{equation}

and the second which represents a branching process

\begin{equation}
 G_{B} = e^{-(\OP{V} - E_0)\delta\tau}
 \label{eq:GB}
\end{equation}

What this tells us, is that we can loop over time steps with a given ensemble of walkers, incorporating the effect of the Green's Functions along the way, and the final distributions of walkers will correspond to that of the direct solution of the \schrodinger. 

Incorporating only the effect of Eq.(\ref{eq:GDiff}) results in a method called \textit{Variational Monte Carlo}. Including the branching term as well results in \textit{Diffusion Monte Carlo}. These methods will be discussed in section REF REF. In either of these methods, diffusion plays an important role. Further simplicity can be achieved by choosing a diffusion model for which closed form expressions for the Green's Functions can be calculated. Two examples of this will be presented in the following sections.



\subsection{Isotropic Diffusion}

Isotropic diffusion is a process in which diffusing particles sees all possible directions as an equally probable path. Eq.~(\ref{Eq:diffusionSimple}) is an example of this. This is the simplest form of a diffusion equation, the case with a linear \textit{diffusion constant}, $D$, and no drift terms.

\begin{equation}
 \frac{\partial P(\vec r, t)}{\partial t} = D\nabla^2 P(\vec r, t) 
 \label{Eq:diffusionSimple}
\end{equation}

In the Quantum Monte Carlo case, the value of the diffusion constant is given by Eq.(\ref{eq:GDiff}), $D=\frac{1}{2}$. 

Say now that we model the diffusion of walkers isotropically, Eq.(\ref{Eq:diffusionSimple}) serves no practical use. In order to achieve specific sampling rules for our walkers, we need a connection between the time-dependence of the distribution (in our case the Wave function in complex time) and the time-dependence of the walker's components in configuration space. This connection is given in terms of a stochastic differential equation called \textit{The Langevin Equation}.

\subsubsection{The Langevin Equation for Isotropic Diffusion}

The Langevin Equation is a stochastic differential equation used in physics to relate the time dependence of a distribution to the time-dependence of the degrees of freedom in the system. For the simple isotropic diffusion described previously, solving the Langevin equation using a Forward Euler approximation for the time derivative results in the following relation:

\begin{eqnarray}
 x_{i+1} = x_i + \xi, \qquad\qquad \sigma(\xi) &=& \sqrt{2D\delta t}, \\
			     \langle\xi\rangle &=& x_i, \nonumber 
\label{eq:langevinSolSimple}
\end{eqnarray}

where $\xi$ is a normal distributed number. This relation is in agreement with the isotropy of Eq.~(\ref{Eq:diffusionSimple}) in the sense that the displacement is symmetric around the current position.


\subsection{Anisotropic Diffusion}

Anisotropic diffusion, in contrast to isotropic diffusion, does not count all directions as equally probable. An example of this is diffusion according to the \textit{Fokker-Planck Equation}, that is, diffusion with a drift term, $\vec F(\vec r, t)$, responsible for pushing the walkers in the direction of configurations with higher probabilities.

\begin{equation}
 \frac{\partial P(\vec r, t)}{\partial t} = D\nabla\cdot\Big[\Big(\nabla - \vec F(\vec r, t)\Big) P(\vec r, t)\Big] 
 \label{Eq:fokkerPlanck}
\end{equation}

The remarkable thing is that simple isotropic diffusion processes obey this relation \cite{abInitioMC}. This means that Quantum Mechanical distributions can be modeled by the Fokker-Planck Equation, leading to a more optimized way of sampling in practical situations. This method of \textit{Importance Sampling} will be discussed in Section~(ref imp). 

In Quantum Monte Carlo we want convergence to a stationary state. We can use this criteria to deduce expression for the drift term given our Quantum Mechanical distribution. A stationary state is obtained when the left hand side of Eq.~(\ref{Eq:fokkerPlanck}) is zero:

\begin{equation*}
 \nabla^2 P(\vec r, t) = P(\vec r, t)\nabla\cdot\vec F(\vec r, t) + \vec F(\vec r, t) \cdot \nabla P(\vec r, t)
\end{equation*}

The next thing we want to achieve is cancellation in the rest of the terms. In order to obtain a Laplacian term on the right hand side to potentially cancel out the one on the left, the drift term needs to be on the form $F(\vec r, t) = g(\vec r, t)\nabla P(\vec r, t)$. Inserting this yields

\begin{equation*}
  \nabla^2 P(\vec r, t) = P(\vec r, t)\frac{\partial g(\vec r, t)}{\partial P(\vec r, t)}\Big|\nabla P(\vec r, t)\Big|^2
  + P(\vec r, t)g(\vec r, t)\nabla^2 P(\vec r, t) + g(\vec r, t) \Big|\nabla P(\vec r, t)\Big|^2.
\end{equation*}

Looking at the factors in front of the Laplacian suggests using $g(\vec r, t) = 1/P(\vec r, t)$. A quick check reveals that this also cancels out the gradient terms, and the resulting expression for the drift term becomes

\begin{eqnarray}
 \vec F(\vec r, t) &=& \frac{1}{P(\vec r, t)}\nabla P(\vec r, t) \nonumber \\
                   &=& \frac{2}{|\psi(\vec r, t)|}\nabla |\psi(\vec r, t)|
\end{eqnarray}

In Quantum Monte Carlo, the drift term is called \textit{The Quantum Force}, since it is responsible for pushing the walkers into regions of higher probabilities, analogous to a force in Newtonian mechanics.

\subsubsection{The Langevin Equation for the Fokker-Planck Equation}

The Langevin equation in the case of a Fokker-Planck Equation has the following form

\begin{equation}
 \frac{\partial x_i}{\partial t} = D F(\vec r, t)_i + \eta,
\end{equation}

where $\eta$ is a so-called \textit{noise term} from stochastic processes. Solving this using the same method as for the isotropic case yields the following sampling rules

\begin{equation}
 x_{i+1} = x_i + DF(\vec r, t)_i\delta t + \xi,
 \label{eq:langevinSolFP}
\end{equation}

where $\xi$ is the same as for the isotropic case. We observe that if the drift term is set to zero, we are back in the isotropic case, just as required. For more details regarding the Fokker-Planck Equation and the Langevin equation, see \cite{Gardiner:2004bk}, \cite{risken1989fpe} and \cite{langevin}.


\subsection{Diffusive Equilibrium Constraints}

Upon convergence of a Markov process, the system at hand will reach its most likely state. This is exactly the behaviour of a real system of diffusing particles described by statistical mechanics: It will \textit{thermalize}, that is, be in its most likely state given a surrounding temperature. Markov processes are hence beloved by physicists; they are simple, yet realistic. 

Once thermalization is reached, average values may be sampled. However, simply spawning a Markov process and waiting for thermalization is an inefficient and unpractical scenario. This may take forever, and it may not; either way its not optimal. We can introduce rules of acceptance and rejection of transitions purposed by following the solutions of the Langevin Equation (Eq.~(\ref{eq:langevinSolSimple}) and Eq.~(\ref{eq:langevinSolFP})), but not without constraints. If any of the following conditions break, we have no guarantee that the system will thermalize properly:

\subsubsection{Detailed Balance} 

For Markov processes, detailed balance is achieved by demanding a \textit{Reversible} Markov process. This boils down to a statistical requirement stating that 

\begin{equation}
 P_iW(i\,\rightarrow\,j) = P_jW(j\,\rightarrow\,i),
 \label{eq:DetailedBalance}
\end{equation}

where $P_i$ is the probability density in configuration $i$, and $W(i\,\rightarrow\,j)$ is the transition probability between states $i$ and $j$. 

\subsubsection{Ergodicity}

Another requirement is that the sampling must be ergodic, that is, the Markov chain (or simpler: The walker) needs to be able to be able to reach any configuration state in the space spanned by the distribution function. It is tempting to define a brute force acceptance rule where only steps resulting in a higher overall probability is accepted, however, this limits the path of the walker, and hence breaks the ergodicity requirement.

\subsection{The Metropolis Algorithm}

The Metropolis Algorithm is a simple set of acceptance/rejection rules used in order to make the thermalization more effective. I will not go into details about transport theory in this section, but rather start the derivation from the criteria of detailed balance, Eq.~(\ref{eq:DetailedBalance}), modeling the transition probability as two-part: $g(i\,\rightarrow\,j)$, the probability of selecting configuration $j$ given configuration $i$, times a probability of accepting the selected move, $A(i\,\rightarrow\,j)$:

\begin{eqnarray}
 P_iW(i\,\rightarrow\,j) &=& P_jW(j\,\rightarrow\,i) \nonumber \\
 P_ig(i\,\rightarrow\,j)A(i\,\rightarrow\,j) &=& P_jg(j\,\rightarrow\,i)A(j\,\rightarrow\,i)
 \label{eq:metro1}
\end{eqnarray}

The idea now is to model $g(i\,\rightarrow\,j)$ as a symmetric function, thus the $g$-terms in Eq.~(\ref{eq:metro1}) cancel. Inserting the probability distribution as the Wave function squared then gives us a simple expression:

\begin{eqnarray}
  |\psi_i|^2A(i\,\rightarrow\,j) &=& |\psi_j|^2A(j\,\rightarrow\,i) \nonumber \\
  \frac{A(j\,\rightarrow\,i)}{A(i\,\rightarrow\,j)} &=& \frac{|\psi_i|^2}{|\psi_j|^2}
  \label{eq:metro2}
\end{eqnarray}

Assume now that configuration $i$ has a higher overall probability than configuration $j$. A more effective termalization is obtained by accepting all these moves, that is $A(i\,\rightarrow\,j) = 1$. What saves us from breaking the criteria of ergodicity is the fact that we do not reject the move otherwise. Instead, we insert $A(i\,\rightarrow\,j) = 1$ into Eq.~(\ref{eq:metro2}), and thus ensuring detailed balance as well as ergodicity.

\begin{equation*}
 A(j\,\rightarrow\,i) = \frac{|\psi_i|^2}{|\psi_j|^2} \qquad\qquad  |\psi_i|^2 < |\psi_j|^2
\end{equation*}


Concatenating both scenarios yields the following acceptance/rejection rules, namely the Metropolis Algorithm:

\begin{equation}
 A(i\,\rightarrow\,j) = \left\{\begin{array}{ccc}
 |\psi_j|^2/|\psi_i|^2& & |\psi_j|^2 < |\psi_i|^2\\
1  & & \mathrm{else}  \end{array}\right.
\label{eq:Metropolis_standard}
\end{equation}

Derived from detailed balance, the Metroplis Algorithm is as a must-have when it comes to Markov Chain Monte Carlo. Besides Quantum Monte Carlo, we have methods such as the \textit{Ising Model} which greatly benefit from these rules \cite{morten}.

\section{Solvers}







