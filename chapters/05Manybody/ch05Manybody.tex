\chapter{Quantum Monte-Carlo}
\label{ch:QMC}

Quantum Monte-Carlo (QMC) is a method for solving Schrödinger's equation using statistical \textit{Markov Chain} (random walk) simulations. The statistical nature of Quantum Mechanics makes Monte-Carlo methods the perfect tool not only for accurately estimating observables, but also for extracting interesting quantities such as densities, i.e.~probability distributions. 

There are multiple strategies which can be used in order to deduce the virtual\footnote{As will be shown, the time parameter in QMC does not correspond to physical time, but rather an imaginary axis at a fixed point in time. Whether nature operates on a complex time plane or not is not testable in a laboratory, and the origin of the probabilistic nature of Quantum Mechanics will thus remain a philosophical problem.} dynamics of QMC, some of which are more mathematically complex than others. In this chapter the focus will be on modelling the Schrödinger equation as a diffusion problem in complex (Wick rotated) time. Other more condensed mathematical approaches does not need the Schrödinger equation at all, however, for the purpose of completeness, this approach will be mentioned only briefly in Section \ref{sec:ConnectAnisIs}.

In this chapter, \textit{Dirac Notation} will be used. See Appendix \ref{app:Dirac} for an introduction. The equations will be in atomic units, i.e.~$\hbar = m_e = e = 4\pi\epsilon_0 = 1$, where $m_e$ and $\epsilon_0$ are the electron mass and the vacuum permittivity, respectively.

\section{Modelling Diffusion}

Like any phenomena involving a probability distribution, Quantum Mechanics can be modelled by a diffusion process. In Quantum Mechanics, the distribution is given by $|\Ph|^2$, the wave function squared. The diffusing elements of interest are the particles in the system at hand. 

The basic idea is to introduce an ensemble of \textit{random walkers}, in which each walker is represented by a position in space at a given time. Once the walkers reach equilibrium, averaging values over the paths of the ensemble will yield average values corresponding to the probability distribution governing the movement of individual walkers. In other words: Counting every walker's contribution within a small volume $\mathrm{d}\mathbf{r}$ will correspond to $|\Ph|^2\mathrm{d}\mathbf{r}$ in the limit of infinite walkers.

Such random movement of walkers are referred to as a \textit{Brownian motion}, named after the British botanist R. Brown, originating from his experiments on plant pollen dispersed in water. Markov chains are a subtype of Brownian motion, where a walkers next move is independent of previous moves. This is the stochastic process in which QMC is described.

The purpose of this section is to motivate the use of diffusion theory in Quantum Mechanics, and to derive the sampling rules needed in order to model Quantum Mechanical distributions by diffusion of random walkers correctly. 

\subsection{Stating the Schrödinger Equation as a Diffusion Problem}
\label{sec:statingDiff}

Consider the time-dependent Schrödinger equation for an arbitrary wave function $\Ph$ using an arbitrary energy shift $E'$

\begin{equation}
 -\frac{\partial \Ph}{i\partial t} = (\OP{H} - E')\Ph.
\end{equation}

Given that the Hamiltonian is time-independent, the formal solution is found by separation of variables in $\Ph$ \cite{griffiths}

\begin{align}
 \OP{H}\Phn &= E\Phn, \label{eq:schrodTimeIndie}\\
 \Ph &= \exp\left(-i(\OP{H} - E')(t-t_0)\right)\Phn. \label{eq:schrodGeneralSolution}
\end{align}

From Eq.~(\ref{eq:schrodGeneralSolution}) it is apparent that the time evolution operator is on the form

\begin{equation}
 \OP{U}(t, t_0) = \exp\left(-i(\OP{H} - E')(t-t_0)\right). \label{eq:TimeEvolOp}
\end{equation}


The time-independent equation is solved for the ground state energy through methods such as \textit{Full Configuration Interaction} \cite{Shavitt} or similar methods based on diagonalizing the Hamiltonian. The time-dependent equation is used by methods such as \textit{Time-Dependent Multi-Configuration Hartree-Fock} \cite{Sigve} in order to obtain the time-development of quantum states. However, neither of the equations originate from, or resemble, diffusion equations. 

The original Schrödinger equation, however, does resemble a diffusion equation in complex time\footnote{The physical time diffusion equation evolves the squared wave function, and can be deduced from the quantum continuity equation combined with Fick's laws of diffusion \cite{QMCDIFF}.}. It can not be treated as a true diffusion equation, since the time evolved quantity, the wave function, is not a probability distribution unless it is squared. However, the equation involves a time derivative and a Laplacian, strongly indicating some sort of connection to a diffusion process.

Substituting complex time with a parameter $\tau$ and choosing the energy shift $E'$ equal to the true ground state energy of $\OP{H}$, $E_0$, the time evolution operator in Eq.~(\ref{eq:TimeEvolOp}) becomes the \textit{projection operation} $\OP{P}(\tau)$, whose choice of name will soon be apparent. In other words:

\begin{align}
t &\to it \equiv \tau,\notag\\
\OP{U}(t, 0) &\to \exp\left(-(\OP{H} - E_0)\tau\right) \equiv \OP{P}(\tau).\notag
\end{align}

Consider an arbitrary wave function $\PT$. Applying the new operator yields a new wave function $\Ptau$ in the following manner

\begin{align}
 \Ptau &= \bra{\mathbf{r}}\OP{P}(\tau)\ket{\Psi_T} \label{eq:projOPonTrial}\\
       &= \bra{\mathbf{r}}\exp\left(-(\OP{H} - E_0)\tau\right)\ket{\Psi_T}. \notag
\end{align}

Expanding the arbitrary state in the eigenfunction of $\OP{H}$, $\ket{\Psi_i}$, yields

\begin{align}
 \Ptau &= \sum_iC_i\bra{r}\exp\left(-(\OP{H} - E_0)\tau\right)\ket{\Psi_i}\notag \\
       &= \sum_iC_i\Psi_i(\mathbf{r})\exp\left(-(E_i - E_0)\tau\right) \notag \\
       &= C_0\Psi_0(x) + \sum_{i=1}^{\infty} C_i\Psi_k(x)e^{-\delta E_i\tau}, \label{eq:schrodGeneralSolution2}
\end{align}

where $C_i = \braket{\Psi_i}{\Psi_T}$ and $\delta E_i = E_i - E_0 \ge 0$. In the limit where $\tau$ goes to infinity, the ground state is the sole survivor of the expression, hence the name projection operator. In other words:

\begin{align}
 \lim_{\tau\to\infty}\Ptau &=  \lim_{\tau\to\infty}\bra{\mathbf{r}}\OP{P}(\tau)\ket{\Psi_T}\notag \\
                           &= C_0\Psi_0(x). \label{eq:ExactProjection}
\end{align}

The projection operator transforms an arbitrary wave function $\PT$, from here on referred to as the \textit{trial wave function}, into the true ground state, given that the overlap $C_0$ is non-zero.

In order to model the projection with Markov chains, the process needs to be split into subprocesses which in turn can be described as transitions in the Markov chain. Introducing a time-step $\delta\tau$, the projection operator can be rewritten as

\begin{equation}
 \OP{P}(\tau) = \prod_{k=1}^n \exp\left(-(\OP{H} - E_0)\delta\tau\right),
\end{equation}

where $n = \tau/\delta\tau$. An important property to notice is that

\begin{equation}
 \OP{P}(\tau + \delta\tau) = \exp\left(-(\OP{H} - E_0)\delta\tau\right)\OP{P}(\tau).
\end{equation}

Using this relation in combination with Eq.~(\ref{eq:projOPonTrial}), the effect of the projection operator during a single time-step is revealed:

\begin{align}
 \Phi(\mathbf{r}, \tau + \delta\tau) &= \bra{\mathbf{r}}\OP{P}(\tau + \delta\tau)\ket{\Psi_T} \notag \\
    &= \bra{\mathbf{r}} \exp\left(-(\OP{H} - E_0)\delta\tau\right)\OP{P}(\tau)\ket{\Psi_T} \notag \\
    &=  \bra{\mathbf{r}} \exp\left(-(\OP{H} - E_0)\delta\tau\right)\ket{\Phi(\tau)} \notag \\
    &= \int_{\mathbf{r}'}\bra{\mathbf{r}}\exp\left(-(\OP{H} - E_0)\delta\tau\right)\ket{\mathbf{r}'}\braket{\mathbf{r}'}{\Phi(\tau)}\mathrm{d}\mbf{r}' \notag \\
    &= \int_{\mathbf{r}'}\bra{\mathbf{r}}\exp\left(-(\OP{H} - E_0)\delta\tau\right)\ket{\mathbf{r}'}\Phi(\mbf{r}', \tau)\mathrm{d}\mbf{r}',
\end{align}

where a complete set of position states were introduced.

For practical purposes, $E_0$ needs to be substituted with an approximation $E_T$ to the ground state energy, commonly referred to as the \textit{trial energy}, in order to avoid self consistency. From Eq.~(\ref{eq:schrodGeneralSolution2}) it is apparent that the projection will still converge as long as $E_T < E_1$, that is, the trial energy is less than that of the first excitation. The resulting expression reads:

\begin{align}
 \Phi(\mathbf{r}, \tau + \delta\tau) &= \int_{\mathbf{r}'}\bra{\mathbf{r}}\exp\left(-(\OP{H} - E_T)\delta\tau\right)\ket{\mathbf{r}'}\Phi(\mbf{r}', \tau)\mathrm{d}\mbf{r}' \\
  &\equiv \int_{\mathbf{r}'}G(\mbf{r}, \mbf{r'}; \delta\tau)\Phi(\mbf{r}', \tau)\mathrm{d}\mbf{r}'.  \label{eq:QMC_GF_EQ}
\end{align}

The equations above are well suited for Markov Chain models, as an ensemble of walkers can be iterated by transitioning between configurations $\ket{\mbf{r}}$ and $\ket{\mbf{r}'}$ with probabilities given by the \textit{Green's function}, $G(\mbf{r}, \mbf{r'}; \delta\tau).$

The effect of the Green's function from Eq.~(\ref{eq:QMC_GF_EQ}) on individual walkers is not trivial. In order to relate the Green's function to well-known processes, the exponential is split into two parts, one containing only the kinetic energy operator $\OP{T} = -\frac{1}{2}\nabla^2$, and the second containing the potential energy operator $\OP{V}$ and the energy shift. This is known as the \textit{short time approximation}\cite{abInitioMC}

\begin{align}
  G(\mbf{r}, \mbf{r'}; \delta\tau) &= \bra{\mathbf{r}}\exp\left(-(\OP{H} - E_T)\delta\tau\right)\ket{\mathbf{r}'} \label{eq:firstTrialEnergyIntro} \\
  &= \bra{\mathbf{r}}e^{-\OP{T}\delta\tau}e^{-(\OP{V} - E_T)\delta\tau}\ket{\mathbf{r}'} + \frac{1}{2}[\OP{V}, \OP{T}]\delta\tau^2 + \mathcal{O}(\delta\tau^3).  \label{eq:shortTimeApprox}
\end{align}

The first exponential describes a transition of walkers governed by the Laplacian, which is a diffusion process. The second exponential is linear in position space and is thus a weighing function responsible for distributing the correct weights to the corresponding walkers. In other words:

\begin{eqnarray}
 G_\mathrm{Diff} &=& e^{\frac{1}{2}\nabla^2\delta\tau},\label{eq:GDiff} \\
 G_\mathrm{B} &=& e^{-(\OP{V} - E_T)\delta\tau} \label{eq:GB},
\end{eqnarray}

where $B$ denotes \textit{branching}. The reasons for this name together with the complete process of modelling weights by branching will be covered in detail in Section \ref{sec:branching}.

The flow of QMC is then to use these Green's functions to propagate the ensemble of walkers into the next time-step. The final distribution of walkers will correspond to that of the direct solution of the Schrödinger equation, given that the time-step is sufficiently small, and the number of cycles $n$ are sufficiently large. These constraints will be covered in more detail later. 

Incorporating only the effect of Eq.~(\ref{eq:GDiff}) results in a method called \textit{Variational Monte-Carlo} (VMC). Including the branching term as well results in \textit{Diffusion Monte-Carlo} (DMC). These methods will be discussed in Sections \ref{sec:VMC} and \ref{sec:DMC}, respectively. In either of these methods, diffusion is a key process.

\section{Solving the Diffusion Problem}
\label{sec:solvingDiff}

The diffusion problem introduced in the previous section uses a symmetric kinetic energy operator implying an \textit{isotropic diffusion}, however, a more efficient kinetic energy operator can be introduced without violating the original equations, resulting in an \textit{anisotropic diffusion} governed by the \textit{Fokker-Planck equation}. These models will be the topic of this section. 

For details regarding the transition from isotropic to anisotropic diffusion, see Section \ref{sec:ConnectAnisIs}.

\subsection{Isotropic Diffusion}

Isotropic diffusion is a process in which diffusing particles sees all directions as an equally probable path. Eq.~(\ref{Eq:diffusionSimple}) is an example of this. The isotropic diffusion equation is  

\begin{equation}
 \label{Eq:diffusionSimple}
 \frac{\partial P(\mbf{r}, t)}{\partial t} = D\nabla^2 P(\mbf{r}, t) .
\end{equation}

This is the simplest form of a diffusion equation, that is, the case with a linear \textit{diffusion constant}, $D$, and no drift terms. 

From Eq.~(\ref{eq:GDiff}) it is clear that the value of the diffusion constant is $D=\frac{1}{2}$, originating from the term scaling the Laplacian in the Schrödinger Equation. An important point is that closed form expressions for the Green's function exists. This closed form expression in the isotropic case is a Gaussian distribution with variance $2D\delta t$ \cite{abInitioMC}

\cfbox{-6pt}{
\begin{equation}
\label{eq:GF_iso}
 G_{\mathrm{Diff}}^{\mathrm{ISO}}(i\,\rightarrow\,j) \propto e^{-|\mbf{r}_i-\mbf{r}_j|^2/4D\delta\tau} .
\end{equation}
}

These equations describe the diffusion process theoretically, however, in order to achieve specific sampling rules for the walkers, a connection between the time-dependence of the distribution and the time-dependence of an individual walker's components in configuration space is needed. This connection is given in terms of a stochastic differential equation called \textit{The Langevin Equation}.

\subsubsection{The Langevin Equation for isotropic diffusion}

The Langevin Equation is a stochastic differential equation used in physics to relate the time dependence of a distribution to the time-dependence of the degrees of freedom in a system. For isotropic diffusion, solving the Langevin equation using a Forward Euler approximation for the time derivative results in the following relation:

\begin{eqnarray}
\label{eq:langevinSolSimple}
 x_{i+1} = x_i + \xi, \qquad\qquad \mathrm{Var}(\xi) &=& 2D\delta t, \\
			     \langle\xi\rangle &=& x_i, \nonumber 
\end{eqnarray}

where $\xi$ is a normal distributed number whose variance matches that of the Green's function in Eq.~(\ref{eq:GF_iso}). This relation is in agreement with the isotropy of Eq.~(\ref{Eq:diffusionSimple}) in the sense that the displacement is symmetric around the current position.


\subsection{Anisotropic Diffusion and the Fokker-Planck equation}
\label{sec:anisFokker}

Anisotropic diffusion, in contrast to isotropic diffusion, does not see all directions as equally probable. An example of this is diffusion according to the \textit{Fokker-Planck Equation}, that is, diffusion with a drift term, $\mbf{F}(\mbf{r}, t)$, responsible for pushing the walkers in the direction of configurations with higher probabilities, and thus closer to an equilibrium state. The Fokker-Planck equation reads:

\begin{equation}
 \label{Eq:fokkerPlanck}
 \frac{\partial P(\mbf{r}, t)}{\partial t} = D\nabla\cdot\Big[\Big(\nabla - \mbf{F}(\mbf{r}, t)\Big) P(\mbf{r}, t)\Big] .
\end{equation}

As will be derived in detail in Section \ref{sec:ConnectAnisIs}, using the Fokker-Planck equation does not violate the original Schrödinger equation, but changes the representation of the ensemble of walkers to a mixed density. This means that QMC can be run with Fokker-Planck diffusion, leading to a more optimized way of sampling due to the drift term. 

As mentioned introductory, the goal of the Markov process is convergence to a stationary state. Using this criteria, the expression for the drift term can be found. A stationary state is obtained when the left hand side of Eq.~(\ref{Eq:fokkerPlanck}) is zero. This yields:

\begin{equation*}
 \nabla^2 P(\mbf{r}, t) = P(\mbf{r}, t)\nabla\cdot\mbf{ F}(\mbf{ r}, t) + \mbf{ F}(\mbf{ r}, t) \cdot \nabla P(\mbf{ r}, t).
\end{equation*}

In order to get cancellation in the remaining terms, the Laplacian term on the right-hand side must cancel out the terms on the left. This implies that the drift term needs to be on the form $\mbf{F}(\mbf{ r}, t) = g(\mbf{ r}, t)\nabla P(\mbf{ r}, t)$. Inserting this yields

\begin{equation*}
  \nabla^2 P(\mbf{ r}, t) = P(\mbf{ r}, t)\frac{\partial g(\mbf{ r}, t)}{\partial P(\mbf{ r}, t)}\Big|\nabla P(\mbf{ r}, t)\Big|^2
  + P(\mbf{ r}, t)g(\mbf{ r}, t)\nabla^2 P(\mbf{ r}, t) + g(\mbf{ r}, t) \Big|\nabla P(\mbf{ r}, t)\Big|^2.
\end{equation*}

The factors in front of the Laplacian suggests using $g(\mbf{ r}, t) = 1/P(\mbf{ r}, t)$. A quick check reveals that this also cancels the gradient terms. The resulting expression for the drift term becomes

\cfbox{3mm -5pt}{
\begin{eqnarray}
 \mbf{ F}(\mbf{ r}, t) &=& \frac{1}{P(\mbf{ r}, t)}\nabla P(\mbf{ r}, t) \nonumber \\
                   &=& \frac{2}{|\psi(\mbf{ r}, t)|}\nabla |\psi(\mbf{ r}, t)|. \\
                   \nonumber
\end{eqnarray}
}


In QMC, the drift term is commonly referred to as the \textit{quantum force}. This is due to the fact that it is responsible for pushing the walkers into regions of higher probabilities, analogous to a force in Newtonian mechanics.

Another strength of the Fokker-Planck equation is that even though the equation itself is more complicated, its Green's function still has a closed form solution. This means that it can be evaluated efficiently. If this was not the case, the practical value would be reduced dramatically. The reason for this will become clear in Section \ref{sec:MetroMain}. The closed form solution reads \cite{abInitioMC}

\cfbox{5mm-7pt}{
\begin{equation}
\label{eq:GF_FP}
 G_\mathrm{Diff}^\mathrm{FP}(i\,\rightarrow j) \propto e^{-(x_i-x_j - D\delta\tau F(x_i))^2/4D\delta\tau}.
\end{equation}
}

As expected, the Green's function is no longer symmetric.

\subsubsection{The Langevin Equation for the Fokker-Planck equation}

The Langevin equation in the case of a Fokker-Planck Equation has the following form

\begin{equation}
 \frac{\partial x_i}{\partial t} = D F(\mbf{r})_i + \eta,
\end{equation}

where $\eta$ is a so-called \textit{noise term} from stochastic processes. Solving this equation using the same method as for the isotropic case yields the following sampling rules

\begin{equation}
 \label{eq:langevinSolFP}
 x_{i+1} = x_i + \xi + DF(\mbf{r})_i\delta t,
\end{equation}

where $\xi$ is the same as for the isotropic case. Observe that when the drift term goes to zero, the Fokker-Planck - and isotropic solutions are equal, just as required. For more details regarding the Fokker-Planck Equation and Langevin equations, see Refs. \cite{Gardiner:2004bk, risken1989fpe, langevin}.


\subsection{Connecting Anisotropic - and Isotropic Diffusion Models}
\label{sec:ConnectAnisIs}

To this point, it might seem far-fetched that switching the diffusion model to a Fokker-Planck diffusion does not violate the original equation, i.e.~the complex time Schrödinger equation (the projection operator). Introducing the distribution function $f(\mbf{r}, t) = \Phi(\mbf{r}, t)\Psi_T(\mbf{r})$, restating the imaginary time Schrödinger equation in terms of $f(\mbf{r}, t)$ yields

\begin{eqnarray}
-\frac{\partial}{\partial t}f(\mbf{r}, t)\,\, = \,\,\Psi_T(\mbf{r})\Big[-\frac{\partial}{\partial t}\Phi(\mbf{r}, t)\Big] &=& \Psi_T(\mbf{r})\left(\OP{H} - E_T\right)\Phi(\mbf{r}, t) \nonumber\\
         &=& \Psi_T(\mbf{r})\left(\OP{H} - E_T\right)\Psi_T(\mbf{r})^{-1}f(\mbf{r}, t) \label{eq:impSamplRaw}\\
         &=& -\frac{1}{2}\Psi_T(\mbf{r})\nabla^2 \left(\Psi_T(\mbf{r})^{-1}f(\mbf{r}, t)\right) + \OP{V}f(\mbf{r}, t) - E_Tf(\mbf{r},t).\nonumber
\end{eqnarray}

Expanding the Laplacian term further reveals

\begin{eqnarray}
K(\mbf{r}, t) &\equiv& -\frac{1}{2}\Psi_T(\mbf{r})\nabla^2 \left(\Psi_T(\mbf{r})^{-1}f(\mbf{r}, t)\right) \nonumber\\
 &=& -\frac{1}{2}\Psi_T(\mbf{r})\nabla\cdot (\nabla\left[\Psi_T(\mbf{r})^{-1}f(\mbf{r}, t)\right]), \\
\nabla\left[\Psi_T(\mbf{r})^{-1}f(\mbf{r}, t)\right] &=& -\Psi_T(\mbf{r})^{-2}\nabla \Psi_T(\mbf{r}) f(\mbf{r}, t) + \Psi_T(\mbf{r})^{-1}\nabla f(\mbf{r}, t).
\end{eqnarray}

Combining these equations and applying the product rule numerous times yield

\begin{eqnarray*}
K(\mbf{r}, t) &=& -\frac{1}{2}\Psi_T(\mbf{r})\Big[\big(2\Psi_T(\mbf{r})^{-3}\left|\nabla\Psi_T(\mbf{r})\right|^2f(\mbf{r}, t) \\
        & & - \Psi_T(\mbf{r})^{-2}\nabla^2\Psi_T(\mbf{r})f(\mbf{r}, t) \\
        & & - \Psi_T(\mbf{r})^{-2}\nabla\Psi_T(\mbf{r})\cdot\nabla f(\mbf{r}, t)\big) \\
        & & + \Psi_T(\mbf{r})^{-1}\nabla^2 f(\mbf{r}, t) \\
        & & - \Psi_T(\mbf{r})^{-2}\nabla\Psi_T(\mbf{r})\cdot\nabla f(\mbf{r}, t)\Big] \\
        &=& - \left|\Psi_T(\mbf{r})^{-1}\nabla\Psi_T(\mbf{r})\right|^2f(\mbf{r}, t) \\
        & & + \frac{1}{2}\Psi_T(\mbf{r})^{-1}\nabla^2\Psi_T(\mbf{r})f(\mbf{r}, t) \\
        & & + \Psi_T(\mbf{r})^{-1}\nabla\Psi_T(\mbf{r})\cdot\nabla f(\mbf{r}, t) \\
        & & - \frac{1}{2}\nabla^2 f(\mbf{r}, t). \\
\end{eqnarray*}

Introducing the following identity helps clean up the messy calculations:

\begin{eqnarray*}
%  \nabla\cdot\left(\Psi_T(\mbf{r})^{-1}\nabla\Psi_T(\mbf{r})\right) &=& -\Psi_T(\mbf{r})^{-2}\left|\nabla\Psi_T(\mbf{r})\right|^2 + \Psi_T(\mbf{r})^{-1}\nabla^2\Psi_T(\mbf{r}) \\
 -\left|\Psi_T(\mbf{r})^{-1}\nabla\Psi_T(\mbf{r})\right|^2 &=& \nabla\cdot\left(\Psi_T(\mbf{r})^{-1}\nabla\Psi_T(\mbf{r})\right) - \Psi_T(\mbf{r})^{-1}\nabla^2\Psi_T(\mbf{r}),
\end{eqnarray*}

which inserted into the expression for $K(\mbf{r}, t)$ reveals

\begin{eqnarray*}
K(\mbf{r}, t) &=&  \nabla\cdot\left(\Psi_T(\mbf{r})^{-1}\nabla\Psi_T(\mbf{r})\right)f(\mbf{r}, t) \\
        & & + \left(\frac{1}{2} - 1\right)\Psi_T(\mbf{r})^{-1}\nabla^2\Psi_T(\mbf{r})f(\mbf{r}, t) \\
        & & + \Psi_T(\mbf{r})^{-1}\nabla\Psi_T(\mbf{r})\cdot\nabla f(\mbf{r}, t) \\
        & & - \frac{1}{2}\nabla^2 f(\mbf{r}, t). \\
\end{eqnarray*}

Inserting the expression for the quantum force $\mbf{F}(\mbf{r}) = 2\Psi_T(\mbf{r})^{-1}\nabla\Psi_T(\mbf{r})$ and the local kinetic energy $K_L(\mbf{r}) = -\frac{1}{2}\Psi_T(\mbf{r})^{-1}\nabla^2\Psi_T(\mbf{r})$ simplifies the expression dramatically

\begin{eqnarray*}
 K(\mbf{r}, t) &=& - \frac{1}{2}\nabla^2 f(\mbf{r}, t) + \frac{1}{2}\underbrace{\left[\mbf{F}(\mbf{r})\cdot \nabla f(\mbf{r}, t) + f(\mbf{r}, t)\nabla\cdot \mbf{F}(\mbf{r})\right]}_{\nabla\cdot\left[\mbf{F} f(\mbf{r}, t)\right]} + K_L(\mbf{r})f(\mbf{r}, t)\\
         &=& \frac{1}{2}\nabla\cdot \left[\left(\nabla - \mbf{F}(\mbf{r})\right)f(\mbf{r}, t)\right] + K_L(\mbf{r})f(\mbf{r}, t).
\end{eqnarray*}

Inserting everything back into Eq.~(\ref{eq:impSamplRaw}) yields

\begin{eqnarray}
 -\frac{\partial}{\partial t}f(\mbf{r}, t) &=& -\frac{1}{2}\nabla\cdot \left[\left(\nabla - \mbf{F}(\mbf{r})\right)f(\mbf{r}, t)\right] + K_L(\mbf{r})f(\mbf{r}, t) + \OP{V}f(\mbf{r}, t) - E_Tf(\mbf{r},t) \nonumber\\
  \frac{\partial}{\partial t}f(\mbf{r}, t)  &=& \frac{1}{2}\nabla\cdot \left[\left(\nabla - \mbf{F}(\mbf{r})\right)f(\mbf{r}, t)\right] - \left(E_L(\mbf{r}) - E_T\right)f(\mbf{r}, t), 
\end{eqnarray}

which is the Fokker-Planck diffusion equation from Eq.~(\ref{Eq:fokkerPlanck}) with a constant shift representing the branching Green's function in the case Fokker-Planck diffusion.

Just as in traditional importance sampled Monte-Carlo integrals, optimized sampling is obtained in QMC by switching distributions into one which exploits known information about the problem at hand. In the case of standard Monte-Carlo integration, the sampling distribution is substituted with one which are similar to the original integrand, resulting in a smoother sampled function, where as in QMC, a distribution is constructed with the sole purpose of imitating the exact ground state in order to suggest moves more efficiently. It is therefore reasonable to call the use of Fokker-Planck diffusion \textit{importance sampled} QMC.

The energy estimated using the new distribution $f(\mbf{r}, t)$ will still equal the exact energy in the limit of convergence. This is demonstrated in the following equations:

\begin{align*}
 E_\mathrm{QMC} &= \frac{1}{N}\int f(\mbf{r}, \tau) \frac{1}{\Psi_T(\mbf{r})} \OP{H} \Psi_T(\mbf{r}) \mathrm{d}\mbf{r} \\
                &= \frac{1}{N}\int \Phi(\mbf{r}, \tau) \OP{H} \Psi_T(\mbf{r}) \mathrm{d}\mbf{r} \\
                &= \frac{1}{N}\bra{\Phi(\tau)}\OP{H}\ket{\Psi_T}, \\
\end{align*}
where 
\begin{align*}
               N&= \int f(\mbf{r}, \tau) \mathrm{d}\mbf{r} \\
                &= \int \Phi(\mbf{r}, \tau)\Psi_T(\mbf{r})\mathrm{d}\mbf{r} \\
                &= \braket{\Phi(\tau)}{\Psi_T},\\
 \end{align*}
which results in the following expression for the energy:
\begin{align*}               
 E_\mathrm{QMC} &= \frac{\bra{\Phi(\tau)}\OP{H}\ket{\Psi_T}}{\braket{\Phi(\tau)}{\Psi_T}}.\\
\end{align*}

Assuming that the walkers have converged to the exact ground state, i.e.~$\ket{\Phi(\tau)}=\ket{\Phi_0}$, letting the Hamiltonian work to the left yields

\begin{align*}
 E_\mathrm{QMC} &= E_0\frac{\braket{\Phi_0}{\Psi_T}}{\braket{\Phi_0}{\Psi_T}} \\
                &= E_0.
\end{align*}

Estimating the energy in QMC will be discussed in detail in Sections \ref{sec:calcExpVals} and \ref{sec:DMC}. 

\section{Diffusive Equilibrium Constraints}

Upon convergence of a Markov process, the ensemble of walkers will on average span the system's most likely state. This is exactly the behavior of a system of diffusing particles described by statistical mechanics: It will \textit{thermalize}, that is, reach equilibrium. 

Once thermalization is reached, expectation values may be sampled. However, simply spawning a Markov process and waiting for thermalization is an inefficient and unpractical scenario. This may take forever, or it may not; either way it is not optimal. Introducing rules of acceptance and rejection on top of the suggested transitions given by the Langevin equation in Eq.~(\ref{eq:langevinSolSimple} or Eq.~(\ref{eq:langevinSolFP}) will result in an optimized sampling. Special care must be taken not to violate necessary properties of the Markov process. If any of the conditions discussed in this section break, there is no guarantee that the system will thermalize properly.

\subsection{Detailed Balance} 

For Markov processes, detailed balance is achieved by demanding a \textit{reversible} Markov process. This boils down to a statistical requirement stating that 

\begin{equation}
 \label{eq:DetailedBalance}
 P_iW(i\,\rightarrow\,j) = P_jW(j\,\rightarrow\,i),
\end{equation}

where $P_i$ is the probability density in configuration $i$, and $W(i\,\rightarrow\,j)$ is the transition probability between states $i$ and $j$. 

\subsection{Ergodicity}

Another requirement is that the sampling must be \textit{ergodic} \cite{robertcasella}, that is, the random walkers need to be able to reach any configuration in the space spanned by the distribution function. It is tempting to define a brute force acceptance rule where only steps resulting in a higher overall probability is accepted, however, this limits the path of the walker, and will thus break the requirement of ergodicity.

\section{The Metropolis Algorithm}
\label{sec:MetroMain}

The Metropolis Algorithm is a simple set of acceptance/rejection rules used in order to make the thermalization more efficient. For a given probability distribution function $P$, the Metropolis algorithm will force sampled points to follow this distribution. 

Starting from the criteria of detailed balance given in Eq.~(\ref{eq:DetailedBalance}, and further introducing a model for the transition probability $W(i\,\rightarrow\,j)$ as consisting of two parts: The probability of selecting configuration $j$ given configuration $i$, $g(i\,\rightarrow\,j)$, times a probability of accepting the selected move, $A(i\,\rightarrow\,j)$, yields

\begin{eqnarray}
 \label{eq:metro1}
 P_iW(i\,\rightarrow\,j) &=& P_jW(j\,\rightarrow\,i), \nonumber \\
 P_ig(i\,\rightarrow\,j)A(i\,\rightarrow\,j) &=& P_jg(j\,\rightarrow\,i)A(j\,\rightarrow\,i).
\end{eqnarray}

Inserting the probability distribution as the wave function squared and the selection probability as the Green's function, the expression becomes

\begin{eqnarray}
  \label{eq:metro2}
  |\psi_i|^2G(i\,\rightarrow\,j)A(i\,\rightarrow\,j) &=& |\psi_j|^2G(j\,\rightarrow\,i)A(j\,\rightarrow\,i), \nonumber \\
  \frac{A(j\,\rightarrow\,i)}{A(i\,\rightarrow\,j)} &=& \frac{G(i\,\rightarrow j)}{G(j\,\rightarrow i)}\frac{|\psi_i|^2}{|\psi_j|^2} \equiv R_G(j\,\rightarrow\,i)R_\psi(j\,\rightarrow\,i)^2,
\end{eqnarray}

where the defined ratios correspond to the Green's function - and wave function ratio, respectively. 

Assume now that configuration $i$ has a higher overall probability than configuration $j$. The essence of the Metropolis algorithm is that the step is automatically accepted, that is, $A(i\,\rightarrow\,j) = 1$. In other words, a more efficient thermalization is obtained by accepting all these moves. What saves Metropolis from breaking the criteria of ergodicity, is the fact that suggested moves to lower probability states are not automatically rejected. This is demonstrated by solving Eq.~(\ref{eq:metro2}) for the case where $A(i\,\rightarrow\,j) = 1$, that is, the case where $P_i < P_j$. This yields

\begin{equation*}
 A(j\,\rightarrow\,i) = R_G(j\,\rightarrow\,i)R_\psi(j\,\rightarrow\,i)^2.
\end{equation*}


Combining both scenarios into one expression yield the following acceptance/rejection rules:

\cfbox{10mm - 14pt}{
\begin{equation}
\label{eq:MetroGeneralGreen}
 A(i\,\rightarrow\,j) = \left\{\begin{array}{ccc}
R_G(i\,\rightarrow\,j)R_\psi(i\,\rightarrow\,j)^2 & & R_G(i\,\rightarrow\,j)R_\psi(i\,\rightarrow\,j)^2 < 1\\
1  & & \mathrm{else}  \end{array}\right. .
\end{equation}
}

This equation can be simplified to

\begin{equation}
  A(i\,\rightarrow\,j) = \min\{R_G(i\,\rightarrow\,j)R_\psi(i\,\rightarrow\,j)^2, \,1\}.
\end{equation}


In the isotropic diffusion case, the Green's function ratio cancels due to symmetry, i.e.~$R_G(i\,\rightarrow\,j) = 1$, resulting in the standard Metropolis algorithm:

\begin{equation}
\label{eq:Metropolis_standard}
 A(i\,\rightarrow\,j) = \min\{R_\psi(i\,\rightarrow\,j)^2, \,1\}.
\end{equation}

On the other hand, for Fokker-Planck diffusion, there will be no cancellation of the Green's functions. Inserting Eq.~(\ref{eq:GF_FP}) into Eq.~(\ref{eq:MetroGeneralGreen}) results in the \textit{Metropolis Hastings algorithm} \cite{robertcasella}. The ratio of the Green's functions can be evaluated efficiently by simply subtracting the exponents of the exponentials. This is best demonstrated by calculating the logarithm

\begin{eqnarray}
 \log{R_G^\mathrm{FP}(i\,\rightarrow\,j)} &=& \log \left(G_\mathrm{Diff}^\mathrm{FP}(j\,\rightarrow i)/G_\mathrm{Diff}^\mathrm{FP}(i\,\rightarrow j)\right) \nonumber \\
                                    &=& \frac{1}{2}\big(F(x_j) + F(x_i)\big)\big(\frac{1}{2}D\delta t(F(x_j) - F(x_i)) + x_i - x_i\big), \\
                                    \nonumber\\
 A(i\,\rightarrow\,j) &=& \min\{\exp \left(\log R_G^\mathrm{FP}(i\,\rightarrow\,j)\right)R_\psi(i\,\rightarrow\,j)^2, \,1\}. \label{eq:MetropolisHastings}
\end{eqnarray}

Derived from detailed balance, the Metroplis Algorithm is an essential part of any Markov Chain Monte-Carlo algorithm. Besides QMC, methods for solving problems such as the \textit{Ising Model} greatly benefit from these rules \cite{morten}.

In practice, without the Metropolis sampling, the ensemble of walkers will not span that of the trial wave function. This is due to the fact that the time-step used in the simulations is finite, and the trial positions of the walkers are random. A chart flow describing the implementation of the Metropolis algorithm and the diffusion process is given in Figure \ref{fig:diffFlowChart}.

\begin{figure}
 \begin{center}
  \includegraphics[scale=0.65]{../Graphics/DiffusionUML.pdf}
  \caption{Flow chart describing the process of iterating a walker through a single time-step, that is, simulation the application of the Green's function from Eq.~(\ref{eq:GDiff}) using the Metropolis algorithm. New positions are suggested according to the chosen diffusion model.}
  \label{fig:diffFlowChart}
 \end{center}
\end{figure}
\clearpage




\section{The Process of Branching}
\label{sec:branching}

In the previous section it became clear that the Metropolis test will guide the walkers to span a distribution representing the trial wave function. This implies that without further action, no changes to the distribution can be made, and the point of modelling the projection operator from Eq.~(\ref{eq:projOPonTrial}) is rendered useless. The important fact to include is that the branching Green's function from Eq.~(\ref{eq:branchFP}) and Eq.~(\ref{eq:branchISO}) distribute weights to the walkers, effectively altering the spanned distribution. 

The process of branching in QMC is simulated by the creation and destruction of walkers with probability equal to that of the branching Green's function \cite{abInitioMC}. The explicit shapes in case of isotropic - (ISO) and anisotropic diffusion (FP) are

\begin{eqnarray}
 G_B^\mathrm{ISO}(i\,\rightarrow j) &=& e^{-\left(\frac{1}{2}\left[V(x_i) + V(x_j)\right] - E_T\right)\delta\tau}\label{eq:branchISO}, \\
 G_B^\mathrm{FP}(i\,\rightarrow j) &=& e^{-\left(\frac{1}{2}\left[E_L(x_i) + E_L(x_j)\right] - E_T\right)\delta\tau}, \label{eq:branchFP}
\end{eqnarray}

where $E_L(x_i)$ is the energy evaluated in configuration $x_i$ (see Section \ref{sec:calcExpVals} for details). The three different scenarios which arise is

\begin{itemize}
 \item $G_B = 1$ : No branching.
 \item $G_B = 0$ : The current walker is to be removed from the current ensemble.
 \item $G_B > 1$ : On average $G_B - 1$ replicas of the current walker are made.
\end{itemize}

Defining the following quantity allows for an efficient simulation of this behavior

\cfbox{1.1cm-10pt}{
\begin{equation}
 \overline{G}_B = \mathrm{floor}\left(G_B + a\right),\label{eq:gbMean}
\end{equation}
}


where $a$ is a uniformly distributed number on $[0,1)$. The probability that $\overline{G}_B = G_B + 1$ is then equal to $G_B - \mathrm{floor}(G_B)$. As an example, assume $G_B = 3.3$. The value of $\overline{G}_B$ is then either three or four, depending on whether $a < 0.7$ or not. The probability that $a<0.7$ is obviously $70\%$, implying that there is a $30\%$ chance that $\overline{G}_B$ is equal to four, and $70\%$ chance that is is equal to three. 

There are some programming challenges due to the fact that the number of walkers is not conserved, such as cleaning up inactive walkers and stabilizing the population across different computational nodes. For details regarding this, see the code documentation at Ref. \cite{libBorealisCode}. Isotropic diffusion is in practice never used with branching due to the singularities in the Coulomb interaction (see Eq.~(\ref{eq:branchISO})). This singularity may cause large fluctuations in the walker population, which is far from an optimal behavior.

The process of branching is demonstrated in Figure \ref{fig:branching}.

\begin{figure}
 \begin{center}
  \includegraphics[scale=0.5]{../Graphics/branching.pdf}
  \caption{The process of branching illustrated. The initial walker $W_i(R, \tau)$ is branched according to the rules of Section \ref{sec:branching}. The numerical value inside the nodes represents the value of $\overline{G}_B$ from Eq.~(\ref{eq:gbMean}). Each horizontal dashed line represent a diffusion step, i.e.~a transition in time. Two lines exiting the same node represent identical walkers. After moving through the diffusion process, no two walkers should ever be equal, given that not all of the steps was rejected by the Metropolis test.}
  \label{fig:branching}
 \end{center}
\end{figure}
\clearpage

\section{The Trial Wave Function}
\label{sec:trialWF}

The initial condition of the QMC calculations, that is, the trial wave function $\PT$, can in principle be chosen to be any normalizable wave function whose overlap with the exact ground state wave function, $\Psi_0(\mathbf{r})$, is non-zero. 

If the overlap is zero, that is, if $C_0=0$ in Eq.~(\ref{eq:ExactProjection}), the formalism breaks down, and no final state of convergence can be reached. On the other hand, the opposite scenario implies the opposite behavior; the closer $C_0$ is to unity, the more rapidly the exact ground state, $\Psi_0(\mathbf{r})$, will become the dominant contribution to the distribution. 

In other words, the trial wave function should be chosen in such a way that the overlap is optimized, i.e.~close to unity. Since the exact ground state is unknown, this overlap has to be optimized based on educated guesses and by forcing known properties of the exact ground state into the approximation. This will be the focus in this section.  

Before getting into specifics, a few notes on many-body theory is needed. From this point on, all particles are assumed to be identical. For more information regarding Quantum Mechanical concepts and many-body theory, see for example Refs. \cite{griffiths, Sakurai:94, Shavitt}. 

\subsection{Many-body Wave Functions}
\label{sec:manyBodyWFs}

Many-body theory arise from the existence of \textit{many-body interactions}, which in this thesis will be truncated at the level of the Coulomb interaction, that is, the two-body interaction. Nature operates using  $N$-body interactions, however, it is overall safe to assume that the contributions beyond Coulomb decrease as the order of the interactions increase. If only one-body interactions were present, as is the case for non-interacting particles, the full system would decouple into $N$ single-particle systems, rendering many-body theory redundant.

Finding the ground state is, not surprisingly, equivalent to solving the time-independent Schrödinger Equation from Eq.~(\ref{eq:schrodTimeIndie}) for the lowest energy eigenvalue, that is

\begin{equation}
 \OP{H}\Psi_0(\mathbf{r}) = E_0\Psi_0(\mathbf{r}),
 \end{equation}
 
where $\mathbf{r} \equiv \{\mathbf{r}_1, \mathbf{r}_2, ..., \mathbf{r}_N\}$ represents the position of every particle. Exact solutions to realistic many-body systems rarely exist, however, like in Section \ref{sec:statingDiff}, expanding the solution in a known basis $\Phi_k(\mathbf{r})$ is always legal, which reduces the problem into that of a \textit{coefficient hunt} 

\begin{equation}
\label{eq:manyBodyExp}
 \Psi_0(\mathbf{r}) = \sum_{k=0}^\infty C_k'\Phi_k(\mathbf{r}),
\end{equation}

where the primed coefficients should not to be confused with the previous coefficients expanding an arbitrary state in the $\Psi_i(\mathbf{r})$ basis (see Eq.~(\ref{eq:schrodGeneralSolution2})). Different many-body methods give rise to different ways of estimating these coefficients, however, certain concepts are necessarily common, for instance truncating the basis at some level, $K$:

\begin{equation}
 \Psi_0(\mathbf{r}) = \sum_{k=0}^K \tilde{C}_k'\Phi_k(\mathbf{r}), \label{eq:manybodyWFexp}
\end{equation}

where $ \tilde{C}_k' \ne  C_k'$ unless $K$ tends to infinity, however, it is overall safe to assume that the value of the coefficients decrease as $k$ increase. 

The many-body basis elements $\Phi_k(\mathbf{r})$ are constructed using $N$ elements from a basis of single-particle wave functions, or \textit{orbitals} for short, where $N$ denotes the total number of particles in the system. In other words, these orbitals, labeled $\phi_n(\mathbf{r}_i)$, combined in different ways give rise to the different many-body wave functions making up the total wave function. The process of calculating basis elements often boils down to an exercise in combinatorics involving combinations of orbitals.

To bring some clarity to the relation between the different wave functions, consider the following example: Imagine electrons surrounding a nucleus, i.e~an atom. A single electron occupying a state with quantum number $n$ at a position $\mathbf{r}_i$ is then described by the orbital $\phi_n(\mathbf{r}_i)$. Each unique\footnote{Two wave functions are considered equal if they differ by nothing but a phase factor.} configuration of electrons (in terms of $n$) will give rise to one unique $\Phi_k(\mathbf{r})$. In other words, the complete basis of $\Phi_k(\mathbf{r})$ is described by the collection of all possible excited states and the ground state. $\Phi_0(\mathbf{r})$ is the ground state of the atom, $\Phi_1(\mathbf{r})$ has one electron exited to a higher shell, $\Phi_2(x)$ has another, and so on. See Figure \ref{fig:AtomicOrbitals} for a demonstration of this. The ordering of the terms in Eq.~(\ref{eq:manybodyWFexp}) are thus chosen to represent higher and higher excitations, i.e.~the states has higher and 
higher energy eigenvalues.

\begin{figure}
 \begin{center}
  \includegraphics[scale=0.5]{../Graphics/shellStructure.pdf}
  \caption{Three different electron configurations in an shell structure making up three different $\Phi_k(\mathbf{r})$, i.e.~constituents of the many-body basis described in Eq.~(\ref{eq:manybodyWFexp}). An electron (solid dot) is represented by e.g.~the orbital $\phi_{1s}(\mathbf{r}_1)$.}
  \label{fig:AtomicOrbitals}
 \end{center}
\end{figure}

To summarize, constructing an approximation to an unknown many-body ground state wave function involves three steps:

\begin{center}
\begin{tabular}{l|l}
 \textbf{Step one}   &  Choose a basis of orbitals $\phi_n(\mathbf{r}_i)$, e.g.~hydrogen states. \\
 \textbf{Step two}   &  Construct $\Phi_k(\mathbf{r})$ from $N\times$ $\phi_n(\mathbf{r}_i)$.   \\
 \textbf{Step three} &  Construct $\Psi_0(\mathbf{r})$ from $K\times$ $\phi_k(\mathbf{r})$.     \\
\end{tabular}
\end{center}

The last step is well described by Eq.~(\ref{eq:manybodyWFexp}), but is seldom necessary to perform explicitly; expressions involving the approximated ground state wave function is given in terms of the constituent $\Phi_k(\mathbf{r})$ elements and their coefficients.

\subsubsection{Step one in detail}

The Hamiltonian of an $N$-particle system is 

\begin{equation}
 \OP{H} = \OP{H}_0 + \OP{H}_\mathrm{I},
\end{equation}

where $\OP{H}_0$ and $\OP{H}_\mathrm{I}$ are the one-body - and the many-body Hamiltonian, respectively. As mentioned in the introduction, the many-body interactions are truncated at the level of the two-body Coulomb interaction. The one-body term consist of the external potential $\OP{u}_\mathrm{ext}(\mathbf{r}_i)$ and the kinetic term $\OP{t}(\mathbf{r}_i)$ for all particles. In order words, the two Hamiltonians are written

\begin{eqnarray}
 \OP{H}_0 &=& \sum_{i=1}^N \OP{h}_0(\mathbf{r}_i) \\
          &=& \sum_{i=1}^N \OP{t}(\mathbf{r}_i) + \OP{u}_\mathrm{ext}(\mathbf{r}_i), \nonumber
  \end{eqnarray}
  and
\begin{eqnarray}
 \OP{H}_\mathrm{I} &\simeq& \sum_{i<j=1}^N \OP{v}(r_{ij}) \\
          &=& \sum_{i<j=1}^N \frac{1}{r_{ij}},  \nonumber
\end{eqnarray}

where $r_{ij} = |\mathbf{r}_i - \mathbf{r}_j|$ is the distance between two particles.

In order to optimize the overlap $C_0$ with the exact wave function, the single-particle orbitals are commonly chosen to be the eigenfunctions of the non-interacting single-particle Hamiltonian, that is

\begin{equation}
\label{eq:orbitalEigenEq}
 \OP{h}_0(\mathbf{r}_i)\phi_n(\mathbf{r}_i) = \epsilon_n\phi_n(\mathbf{r}_i).
\end{equation}

If no such choice can be made, choosing, free-particle solutions, Laguerre polynomials, or similar, is the general strategy. However, for these bases, the expansion truncation $K$ from Eq.~(\ref{eq:manybodyWFexp}) needs to be higher in order to achieve a satisfying overlap.  


\subsubsection{Step two in detail}

In the case of \textit{fermions}, that is, half-integer spin particles like electrons, protons, etc., $\Phi_k(\mathbf{r})$ is an anti-symmetric function\footnote{Interchanging two particles in an anti-symmetric wave function will reproduce the state changing only the sign.} on the form of a determinant: The so-called \textit{Slater determinant}. The shape of the determinant is given in Eq.~(\ref{eq:SlaterDeterminantExplicit}). The anti-symmetry is a direct consequence of the \textit{Pauli Exclusion Principle}: At any given time, two fermions cannot occupy the same state. 

Bosons, on the other hand, have symmetric wave functions, which in many ways are easier to deal with because of the lack of an exclusion principle. The bosonic many-body wave function is given in Eq.~(\ref{eq:BosonicWFExplicit}). In order to keep the terminology less abstract and confusing, the focus will be on systems of fermions from here on.

\cfbox{1.2cm-6pt}{
\begin{eqnarray}
\label{eq:SlaterDeterminantExplicit}
\Phi_0^\mathrm{AS}(\mbf{r}_1, \mbf{r}_2, ..., \mbf{r}_N) &\propto& \sum_\mathrm{P} (-)^\mathrm{P} \OP{P}\phi_1(\mbf{r}_1)\phi_2(\mbf{r}_2)\,...\,\phi_N(\mbf{r}_N) \nonumber\\
\nonumber\\
&=&\left| \begin{array}{cccc}
\phi_1(\mbf{r}_1) & \phi_2(\mbf{r}_1)& \cdots & \phi_N(\mbf{r}_1) \\
\phi_1(\mbf{r}_2) & \phi_2(\mbf{r}_2)& \cdots & \phi_N(\mbf{r}_2) \\
\vdots & \vdots& \ddots & \vdots \\
\phi_1(\mbf{r}_N) & \phi_2(\mbf{r}_N)& \cdots & \phi_N(\mbf{r}_N) \\
 \end{array} \right|, \\
\nonumber\\
\nonumber\\
 \label{eq:BosonicWFExplicit}
 \Phi_0^\mathrm{S}(\mbf{r}_1, \mbf{r}_2, ..., \mbf{r}_N) &\propto& \sum_\mathrm{P} \OP{P}\phi_1(\mbf{r}_1)\phi_2(\mbf{r}_2)\,...\,\phi_N(\mbf{r}_N).
\end{eqnarray}
}

The permutation operator $\OP{P}$ is simply a way of writing \textit{in any combination of particles and states}, hence the combinatoric exercise mentioned previously. Any combination of $N$ orbital elements $\phi_n(\mbf{r}_i)$ can be used to produce different $\Phi_k(\mathbf{r})$. For illustrative purposes, and for the purpose of this thesis in general where a single determinant ansatz is used, only the ground state has been presented.  

\subsubsection{Dealing with correlations}

The contributions to the ground state on the right-hand side in Eq.~(\ref{eq:manyBodyExp}) for $k>0$ are referred to as \textit{correlation} terms. Given that the single-particle wave functions are chosen by Eq.~(\ref{eq:orbitalEigenEq}), the existence of the correlation terms, i.e.~$C_k' \ne 0$ for $k>0$, follows as a direct consequence of the electron-electron interaction, hence the name.

As an example, imagine performing an energy calculation with two particles being infinitely close; the Coulomb singularity will cause the energy to blow up. However, if the calculations are performed using the exact wave function, the diverging terms will cancel out; the energy eigenvalue is independent of the position of the state. 

In other words, a necessary property of the exact wave function is that the singularities in the many-body interactions are canceled. The basic idea is thus to make sure the trial wave function also has this property. By doing so, it is brought closer to the exact wave function.

These criteria are called \textit{cusp conditions} \cite{morten}, and serve as powerful guides when it comes to selecting an optimal trial wave function. 


\subsection{Choosing the Trial Wave Function}
\label{sec:ChoiceTrialWF}

To recap, choosing the trial wave function boils down to optimizing the overlap $C_0 = \braket{\Psi_0}{\Psi_T}$ using a priori knowledge about the system at hand. As discussed previously, the optimal choice of single-particle basis is the eigenfunctions of the non-interacting case (given that they exist). Starting from Eq.~(\ref{eq:manybodyWFexp}), from here on referred to as the \textit{spatial wave function}, the first step is to make sure the cusp conditions are obeyed.

Introducing the correlation functions $f(r_{ij})$, where $r_{ij}$ is the relative distance between particle $i$ and $j$, the general ansatz for the trial wave function becomes

\begin{equation}
\label{eq:firstAnzatsTWF}
 \Psi_T(\mbf{r}_1, ..., \mbf{r}_N) = \Big[\sum_{k=0}^K C_k\Phi_k(\mbf{r}_1, ..., \mbf{r}_N)\Big]\prod_{i<j}^Nf(r_{ij}).
\end{equation}

The idea is now to choose $f(r_{ij})$ in such a way that the cusp conditions are obeyed. This should, in light of previous discussions, reduce the amount of terms needed in the spatial wave function to obtain a satisfying overlap.

\subsubsection{Explicit shapes}

Several models for the correlation function exist, however, some are less practical than others. An example given in ref. \cite{abInitioMC} demonstrates this nicely: Hylleraas presented the following correlation function 

\begin{equation}
 f(r_{ij})_\mathrm{Hylleraas} = e^{-\frac{1}{2} (r_i + r_j)}\sum_k d_k(r_{ij})^{a_k} (r_i + r_j)^{b_k}(r_i - r_j)^{e_k},
\end{equation}

where all $k$-subscripted parameters are free. Calculating the helium ground state energy using this correlation function with nine terms yields a four decimal precision. Eight digit precision is achieved by including 1078 terms. For the purpose of QMC, including such vast amounts of parameters is out of the question. The strength of QMC is that very good results can be obtained using a very simple ansatz to the wave function. 

A commonly used correlation function in studies involving few variational parameters is the \textit{Padé Jastrow} function

\begin{eqnarray*}
 \prod_{i<j}^Nf(r_{ij}) &=& \exp(U), \\
         U &=&  \sum_{i<j}^N\left(\frac{\sum_k a_kr_{ij}^k}{1 + \sum_k \beta_kr_{ij}^k}\right) + \sum_i^N\left(\frac{\sum_k a'_kr_i^k}{1 + \sum_k \alpha_kr_i^k}\right).
\end{eqnarray*}

For systems where the correlations are relatively well behaved, it is custom to drop the second sum all together, and keep only the $k=1$ term from the first. The resulting function reads

\begin{equation}
 \label{eq:jastrow}
 f(r_{ij}; \beta) = \exp\left(\frac{a_{ij} r_{ij}}{1 + \beta r_{ij}}\right),
\end{equation}

where $\beta$ is a variational parameter, and $a_{k=1} \equiv a_{ij}$ is a constant depending on the relative spin-orientation of particles $i$ and $j$ tuned in such a way that the cusp conditions are obeyed. For three dimensions, $a_{ij} = 1/4$ or $a_{ij} = 1/2$ depending on whether or not the spins of $i$ and $j$ are parallell or anti parallell, respectively\cite{abInitioMC}. For two dimensions, the values are $a_{ij}=1/3$ (parallell) or $a_{ij}=1$ (anti-parallel)\cite{larseivind}. This is the correlation function used for all systems in this thesis.

Shifting the focus back to the spatial wave function, in the case of a fermionic system, the evaluation of an $N\times N$ Slater determinant severely limits the efficiency of many-particle simulations. However, assuming the Hamiltonian to be spin-independent, the eigenstates for different spin eigenvalues will be identical. This fact results in the spatial wave function being split in two: One part for each spin eigenvalue. A detailed derivation of this is given in the appendix of Ref. \cite{QMCPHD2008}. The resulting wave function thus becomes

\begin{equation}
 \Psi_T(\mathbf{r}; \beta) = \Big[\sum_{k=0}^K C_k'\tilde\Phi_k(\mbf{r}_1, ..., \mbf{r}_{\frac{N}{2}})\tilde\Phi_k(\mbf{r}_{\frac{N}{2}-1}, ..., \mbf{r}_{N})\Big]\prod_{i<j}^Nf(r_{ij}; \beta). \label{eq:splitSlater}
\end{equation}

Due to the identical nature of the particles, they may be arbitrarily ordered. For simplicity, the first half represents spin up, and the second half spin down. The spin up determinant will from here on be labeled $|\mathbf{S}^\uparrow|$, and the spin down one $|\mathbf{S}^\downarrow|$, where the $\mathbf{S}$ matrix will be referred to as the \textit{Slater matrix}. Stitching everything together, the explicit shape of the trial wave function becomes

\cfbox{1.5cm-8pt}{
\begin{equation}
\label{eq:MultiDeterminantTWF}
 \Psi_T(\mbf{r}_1, ..., \mbf{r}_N; \beta) = \sum_{k=0}^K C_k' |\mathbf{S}^\uparrow|_k|\mathbf{S}^\downarrow|_k\prod_{i<j}^Nf(r_{ij}; \beta).
\end{equation}
}

This shape is referred to as a \textit{multi-determinant} trial wave function unless $K=1$, in which it will be referred to as a \textit{single-determinant} trial wave function.

\subsubsection{Limitations}

Depending on the complexity of the system at hand, more complicated trial wave functions might be needed to obtain reasonable convergence. However, it is important to distinguish between simply integrating a trial wave function, and performing the full diffusion calculation. As a reminder: Simple integration will not be able to alter the distribution; what you have is what you get. Solving the diffusion problem, on the other hand, will alter the distribution from that of the trial wave function ($\tau = 0$) into a distribution closer to the exact wave function by Eq.~(\ref{eq:schrodGeneralSolution2}). 

Because of this fact, limitations due to the trial wave function in full\footnote{``Full'' in the sense that all Green's functions are applied. As will be revealed later, VMC corresponds to a standard importance sampled Monte-Carlo integration by omitting the branching process.} QMC is far less than what is the case of standard Monte-Carlo integration. A more complex trial wave function might convergence faster, but at the expense of being more CPU-intensive. This implies that CPU-time per walker can be traded for convergence time. For systems of many particles, the CPU-time per walker needs to be as low as possible in order to get the computation done in a reasonable amount of time. In other words, the choice of trial wave function needs to be done in light of the system at hand, and the specific aim of the computation. 

On the other hand, when the number of particles in the system increase, it is safe to assume that the quality of the trial wave function will decrease. This is demonstrated in Ref. \cite{UmrigarMolecules}, where calculations for $\mathrm{F}_2$ (18 particles) need an increase in the number of determinants to achieve a result with the same precision as calculations for $\mathrm{O}_2$ (16 particles).  

\subsubsection{Single-determinant trial wave functions}

In the case of well-behaving systems, a single determinant with a simple Jastrow factor serves as a reasonable trial wave function. This simplicity opens up the possibility of simulating large systems efficiently.  More details regarding this will be given in Section \ref{sec:optSingleSlater}. 

In order to further optimize the overlap with the exact wave function, a second variational parameter $\alpha$ is introduced in the spatial wave function

\cfbox{8mm}{
\begin{equation}
\label{eq:singleDeterminantTWF}
 \Psi_T(\mbf{r}_1, ..., \mbf{r}_N; \alpha, \beta) = D^\uparrow(\alpha)D^\downarrow(\alpha)\prod_{i<j}^Nf(r_{ij}; \beta).
\end{equation}
}

Determining the optimal values of the variational parameters will be the topic of the next section. If the introduction of the variational parameter was redundant, optimizations would simply yield $\alpha=1$. 


\subsection{Selecting Optimal Variational Parameters}
\label{sec:selectingOptVarPar}

All practical ways of determining the optimal values of the variational parameters originate from the same powerful principle: \textit{The Variational Principle}. The easiest way of demonstrating the principle is to evaluate the expectation value of the energy, using an approach similar to what used in Eq.~(\ref{eq:schrodGeneralSolution2}). Consider the following relations

\begin{eqnarray*}
 E_k &=& \bra{\Psi_k}\OP{H}\ket{\Psi_k},  \\
 E   &=& \bra{\Psi_T(\alpha, \beta)}\OP{H}\ket{\Psi_T(\alpha, \beta)}\\
     &=& \sum_{kl} C_k^\ast C_l \underbrace{\bra{\Psi_k}\OP{H}\ket{\Psi_l}}_{E_k\delta_{kl}} \\
     &=& \sum_k |C_k|^2E_k.
\end{eqnarray*}

Just as with the projection operator, introducing $E_k = E_0 + \delta E_k$ where $\delta E_k \ge 0$ will simplify the arguments

\begin{eqnarray*}
 E   &=& \sum_k |C_k^2| (E_0 + \delta E_k) \\
     &=& E_0 \underbrace{\sum_k |C_k^2|}_{1} + \underbrace{\sum_k |C_k|^2\delta E_k}_{\ge 0} \\
     &\ge& E_0.
\end{eqnarray*}

The conclusion is remarkable: No matter which trial wave function is used, the resulting energy will always be greater or equal to the exact ground state energy. This implies that the problem of choosing variational parameters comes down to a minimization problem in the parameters space

\begin{equation}
\label{eq:varMin}
\frac{\partial \langle E\rangle}{\partial \alpha_i} = \frac{\partial}{\partial \alpha_i}\bra{\Psi_T(\alpha_i)}\OP{H}\ket{\Psi_T(\alpha_i)} = 0
\end{equation}

In order to work with Eq.~(\ref{eq:varMin}) in practice, it needs to be rewritten in terms of known values. Since the wave function depends on the variational parameter, the normalization factor needs to be included in the expression of the expectation value. Applying the product rule numerous times yields

\newcommand{\Norm}{\braket{\Psi_T(\alpha_i)}{\Psi_T(\alpha_i)}}

\begin{eqnarray*}
 \frac{\partial \langle E\rangle}{\partial \alpha_i}  &=& \frac{\partial}{\partial \alpha_i} \frac{\bra{\Psi_T(\alpha_i)}\OP{H}\ket{\Psi_T(\alpha_i)}}{\Norm} \\
 &=& \frac{\left(\bra{\Psi_T(\alpha_i)}\frac{\partial}{\partial \alpha_i}\OP{H}\ket{\Psi_T(\alpha_i)} + \bra{\Psi_T(\alpha_i)}\OP{H}\frac{\partial}{\partial \alpha_i}\ket{\Psi_T(\alpha_i)}\right)}{\Norm^2}\Norm \\
 &-& \bra{\Psi_T(\alpha_i)}\OP{H}\ket{\Psi_T(\alpha_i)}\frac{\left(\bra{\Psi_T(\alpha_i)}\frac{\partial}{\partial \alpha_i}\right)\ket{\Psi_T(\alpha_i)} + \bra{\Psi_T(\alpha_i)}\left(\frac{\partial}{\partial \alpha_i}\ket{\Psi_T(\alpha_i)}\right)}{\Norm^2}.\\
\end{eqnarray*}

The Hamiltonian does not depend on the variational parameters, hence both terms in the first expansion is equal. Cleaning up the expression yields

\cfbox{2cm-10pt}{
\begin{eqnarray}
 \frac{\partial \langle E\rangle}{\partial \alpha_i} &=& 2\left(\frac{\bra{\Psi_T(\alpha_i)}\OP{H}\frac{\partial}{\partial \alpha_i}\ket{\Psi_T(\alpha_i)}}{\Norm} - \langle E \rangle\frac{\bra{\Psi_T(\alpha_i)}\frac{\partial}{\partial \alpha_i}\ket{\Psi_T(\alpha_i)}}{\Norm} \right) \nonumber \\
  &=& 2\left(\left< E \frac{\partial \Psi_T}{\partial \alpha_i} \right> -\left< E\right>\left<\frac{\partial \Psi_T}{\partial \alpha_i} \right> \right). \label{eq:varParGrad} \\
  \nonumber
\end{eqnarray}
}

In the case of $\Psi_T(\mathbf{r}; \alpha_i)$ being represented by a Slater determinant, the relationship between the variational derivative of the determinant and the variational derivative of the single-particle orbitals $\phi_n(\mathbf{r}_i; \alpha_i)$ is

\cfbox{2cm-5pt}{
\begin{equation}
 \frac{\partial \Psi_T(\mathbf{r}; \alpha_i)}{\partial \alpha_i} = \sum_{p=1}^N\sum_{q=0}^{N/2} \phi_q(\mathbf{r}_p; \alpha_i) \left[\frac{\partial \phi_q(\mathbf{r}_p; \alpha_i)}{\partial \alpha_i}\right]\mathbf{S}^{-1}_{qp},
\end{equation}
}

where $\mathbf{S}^{-1}_{qi}$ is the inverse of the Slater matrix, which will be discussed in more detail in Section \ref{sec:optSlaterRat}. 

Using these expressions for the \textit{variational energy gradient}, the derivatives can be calculated exactly the same way the energy. The gradient can then be used to move in the direction of the variational minimum in Eq.~(\ref{eq:varMin}). 

This strategy gives rise to numerous ways of finding the optimal parameters, such as using the well known Newton's method, conjugate gradient methods \cite{golub1996matrix}, steepest descent (similar to Newton's method), and many more. 
The method implemented for this thesis is called \textit{Adaptive Stochastic Gradient Descent}, and is an efficient iterative algorithm for seeking the variational minimum. The gradient descent methods will be covered in Section \ref{sec:GradientDescent}.

\subsection{Calculating Expectation Values}
\label{sec:calcExpVals}

The expectation value of an operator $\OP{O}$ is obtained by sampling \textit{local} values, $O_L(x)$

\begin{eqnarray}
 \bra{\Psi_T}\OP{O}\ket{\Psi_T} &=& \int \Psi_T(x)^\ast \OP{O} \Psi_T(x)\mathrm{d}x \nonumber\\
                                &=& \int |\Psi_T|^2\left(\frac{1}{\Psi_T(x)}\OP{O}\Psi_T(x)\right)\mathrm{d}x \nonumber\\
                                &=& \int |\Psi_T|^2 O_L(x)\mathrm{d}x. \\
                         O_L(x) &=& \frac{1}{\Psi_T(x)}\OP{O}\Psi_T(x).           
\end{eqnarray}

Discretizing the integral yields 

\begin{equation}
 \bra{\Psi_T}\OP{O}\ket{\Psi_T} \equiv \Exp{O} \simeq \frac{1}{n}\sum_{i=1}^n O_L(x_i) \equiv \overline{O},
\end{equation}

where $x_i$ is a random variable taken from distribution of the trial wave function. The \textit{ensemble average},  $\Exp{O}$ will, given ergodicity, equal the estimated average $\overline{O}$ in the limit $n\rightarrow\infty$, that is

\begin{equation}
 \label{eq:MeanVStrueExp}
 \Exp{O} = \lim_{n\to\infty} \overline{O} = \lim_{n\to\infty}\frac{1}{n}\sum_{i=1}^n O_L(x_i).
\end{equation}


In the case of the energy estimation, this implies that once the walkers reach equilibrium, local values can be sampled based on their configurations $\mathbf{r}_i$ (remember that Metropolis ensures that the walkers follow $|\PT|^2$). In the case of energies, the explicit expression becomes

\begin{equation}
 \langle E \rangle \simeq \frac{1}{n}\sum_{i=1}^n \left(\frac{1}{\Psi_T(\mathbf{r}_i)}\left(-\frac{1}{2}\nabla^2\right)\Psi_T(\mathbf{r}_i) + V(\mathbf{r}_i)\right).
\end{equation}

Incorporating the branching Green's function $G_B$ into the above equation is covered in the DMC section.

\subsection{Normalization}

Every explicit calculation using the trial wave function in QMC involves taking ratios. Calculating ratios implies a cancellation in the normalization factors. Eq.~(\ref{eq:MetroGeneralGreen}) from the Metropolis section, the quantum force in the Fokker-Planck equation, and the sampling of local values described in the previous section demonstrate exactly this; everything involves ratios.

Not having to normalize the wave functions does not only save a lot of CPU-time, but it also removes the need of including the normalization factors of the single-particle wave functions; any constants multiplying $\phi_n(x_i)$ in Eq.~(\ref{eq:SlaterDeterminantExplicit}) and Eq.~(\ref{eq:BosonicWFExplicit}) can be taken outside the sum over permutations, and will thus cancel when the ratio between two wave functions constituting of the same single-particle orbitals are computed. 

Note, however, that this argument is valid for single determinant wave functions only. 

\section{Gradient Descent Methods}
\label{sec:GradientDescent}

The direction of a gradient serves as a guide to extremal values. Gradient descent, also called steepest descent\footnote{In literature, steepest - and gradient descent are sometimes referred to as being different. However, for simplicity, these will not be differentiated.}, is a family of minimization methods using this property of gradients in order to backtrace a local minimum in the vicinity of an initial guess. 

\subsection{General Gradient Descent}

Seeking maxima or minima is simply a question of whether the positive or the negative direction of the gradient is followed.
Imagine a function $f(x)$, with a minimum residing at $x=x_m$. The information at hand is then

\begin{eqnarray}
 \nabla f(x_m) &=& 0 \\
 \nabla f(x_m - \mathrm{d}x) &<& 0 \\
  \nabla f(x_m + \mathrm{d}x) &>& 0
\end{eqnarray}

where $\mathrm{d}x$ is a infinite decimal displacement. 

\begin{figure}
 \begin{center}
  \includegraphics[scale=0.3]{../Graphics/SGD.pdf}
  \caption{Two steps of a one dimensional Gradient Descent process. Steps are taken in the direction of the negative gradient (indicated by dotted lines).}
  \label{fig:SGD}
 \end{center}
\end{figure}

As an example, imagine starting from an initial guess $x_0$. The direction of the gradient is then calculated and followed a number of steps. From Figure \ref{fig:SGD} and the previous equations, it is clear that crossing the true minimum induces a sign change in the gradient. The brute force way of minimizing is to simply end the calculation at this point, however, this would require an extreme amount of very small steps in order to achieve good precision. 

The difference equation describing the steps from the previous paragraph is

\begin{equation}
 x_{i+1} = x_i - \delta\frac{\nabla f(x_i)}{|\nabla f(x_i)|}.
\end{equation}


An improved algorithm would be to continue iterating even though the minimum is crossed, however, this would cause the constant step-length algorithms to oscillate between two points, e.g.~$x_1$ and $x_2$ in Figure \ref{fig:SGD}. To counter this, a changing step-length $\delta_i$ is introduced

\cfbox{2.2cm-8pt}{
\begin{equation}
\label{eq:SGD}
  x_{i+1} = x_i - \delta_i\nabla f(x_i).
\end{equation}
}


All gradient/steepest descent methods are in principle described by Eq.~(\ref{eq:SGD})\footnote{This fact sets the perfect scene for an object oriented implementation of gradient descent methods.}. Some examples are

\begin{listliketab}
\storestyleof{itemize}
 \begin{tabular}{l l}
  \textbullet  \,Brute Force I   &  $\delta_i = \delta \frac{1}{|\nabla f(x_i)|}$ \\
  \textbullet  \,Brute Force II  &  $\delta_i = \delta $ \\
  \textbullet  \,Monotone Decreasing &  $\delta_i = \delta / i^{N}$ \\
  \textbullet  \,Newton's Method &  $\delta_i = \frac{1}{\nabla^2 f(x_i)}$\\
 \end{tabular}
\end{listliketab}

Iterative gradient methods will only reveal one local extrema, depending on the choice of $x_0$ and $\delta$. In order to find several extrema, multiple unique processes can be run sequentially or in parallel with different initial guesses.

\subsection{Stochastic Gradient Descent}

Minimizing stochastic quantities such as the variance and expectation values adds another layer of complications on top of the methods introduced in the previous section. Assuming a closed form expression for the stochastic quantity is unobtainable, the gradient needs to be calculated by using e.g.~Monte-Carlo sampling. Eq.~(\ref{eq:varParGrad}) is an example of such a process.

A precise sampling of the stochastic quantities is expensive and unpractical. Stochastic gradient methods use different techniques in order to make the sampling more effective, such as multiple walkers, thermalization, and more. 

Using a finite difference scheme with stochastic quantities is dangerous, as uncertainties in the values will cause the gradient to become unstable when the variations are low close to the minimum. This is illustrated in Figure \ref{fig:sSGD}.

\begin{figure}
 \begin{center}
  \includegraphics[scale=0.3]{../Graphics/SSGD.pdf}
  \caption{A one dimensional plot of an expectation value function. Smeared lines are representing uncertainties due to rough sampling. The direction of the local gradient (solid green line) at a point $x_i$ is not necessarily a good estimate of the actual analytic gradient (dashed red line).}
  \label{fig:sSGD}
 \end{center}
\end{figure}


\subsection{Adaptive Stochastic Gradient Descent}

Adaptive Stochastic Gradient Descent (ASGD) has its roots in the mathematics of automated control theory \cite{ASGD_MB}. The automated process is that of choosing an optimal step-length $\delta_i$ for the current transition $x_{i}\to x_{i+1}$. This process is based on the inner product of the old and the new gradient though a variable $X_i$

\begin{equation}
\label{eq:ASGD_X_i}
 X_i \equiv -\nabla_i\cdot \nabla_{i-1}.
\end{equation}

The step-length from Eq.~(\ref{eq:SGD}) is modelled in the following manner in ASGD:

\begin{eqnarray}
 \delta_i   &=& \gamma(t_i) \\
 \gamma(t)  &=& a/(t + A) \label{eq:ASGD_delta_i}\\
 t_{i+1}    &=& \max(t_i + f(X_i), 0) \label{eq:ASGD_t_i}\\
 f(x)       &=& f_\mathrm{min} + \frac{f_\mathrm{max} - f_\mathrm{min}}{1 - (f_\mathrm{max}/f_\mathrm{min})e^{-x/\omega}}\label{eq:ASGD_f_i}
\end{eqnarray}

with $f_\mathrm{max} > 0$, $f_\mathrm{min} < 0$, and $\omega > 0$. The free parameters are $a$, $A$ and $t_0$, however, Ref. \cite{ASGD} suggests $A=20$ and $t_0=t_1=A$ for universal usage.

Notice that the step-length increase if $t_i$ decrease and vice-versa. A smaller step-length is sought for regions close to the minimum. The function $f(x)$ is responsible of altering the step-length by changing the trend of $t$. Close to the minimum, a smaller step-length is sought, and hence $t$ must increase. Being close to the minimum implies that the gradient changes sign frequently. Crossing the minimum with ASGD has the following consequence

\begin{itemize}
 \item Eq.~(\ref{eq:ASGD_X_i}): The value of $X_i$ will be positive.
 \item Eq.~(\ref{eq:ASGD_f_i}): $f(X_i)$ will return a value in $[0, f_\mathrm{max}]$ depending on the magnitude of $X_i$.
 \item Eq.~(\ref{eq:ASGD_t_i}): The value of $t$ will increase, i.e.~$t_{i+1} > t_i$.
 \item Eq.~(\ref{eq:ASGD_delta_i}): The step-length will decrease.
\end{itemize}

The second step regarding $f(X_i)$ can be visualized in Figure \ref{fig:f_ASGD}.

\begin{figure}
 \begin{center}
  \includegraphics[scale=0.75]{../Graphics/ASGD_f.pdf}
  \caption{Examples of $f(X_i)$ as published in Ref. \cite{ASGD}. As $\omega\to0$, $f(x)$ approaches a step function.}
  \label{fig:f_ASGD}
 \end{center}
\end{figure}

\subsubsection{Assumptions}

These assumptions are selected direct citations from Ref. \cite{ASGD}. They are listed in order to give an impression that the shapes of the functions used in ASGD are not selected at random, but carefully chosen to work optimally in a stochastic space with averages estimated using very few samples.

\begin{itemize}
 \item The statistical error in the sampled gradients are distributed with zero mean.
\end{itemize}

This is shown in Ref. \cite{ASGD}; they are normally distributed. The implication is that upon combining gradient estimates for $N$ different processes, the accumulative error will tend to zero quickly.

\begin{itemize}
 \item The step-length $\gamma(t)$ is a positive monotone decreasing function defined on $[0,\infty)$ with maximum at $t=0$.
\end{itemize}

With $\gamma(t)$ being as in Eq~(\ref{eq:ASGD_delta_i}), this is easily shown.

\begin{itemize}
 \item The function $f(x)$ is continuous and monotone increasing with $f_\mathrm{min} = \displaystyle\lim_{x\to\infty} f(x)$ and $f_\mathrm{max} =  \displaystyle\lim_{x\to-\infty} f(x)$.
\end{itemize}

This is exactly the behavior displayed in Figure \ref{fig:f_ASGD}.

\subsubsection{Implementation}

A flow chart of the implementation is given in Figure \ref{fig:ASGD_flow}. For specific details regarding the implementation, see the documentation of the code in Ref. \cite{libBorealisCode}. An example of minimization using ASGD is given in Figure \ref{fig:ASGD_Ex}. 

\begin{figure}[h]
 \begin{center}
  \subfigure{\includegraphics[scale=0.37]{../Graphics/ASGD_min_paramGrad_ex.png}}
  \subfigure{\includegraphics[scale=0.37]{../Graphics/ASGD_min_step_ex.png}} 
  \caption{Results of Adaptive Stochastic Gradient Descent used on a two-particle quantum dot with unit oscillator frequency using $400$ cycles pr. gradient sampling and $40$ independent walkers. The right figure shows the evolution of the time-step. The left figure shows the evolution of the variational parameters $\alpha$ and $\beta$ introduced in Section \ref{sec:trialWF} on top, and the evolution of the gradients on the bottom. The gradients are averaged to reveal the pattern underlying the noise. Dispite this averaging, it is apparent that they tend to zero, $\beta$ somewhat before $\alpha$. The step rushes to zero with a small rebound as it attempts to cross to negative values.}
  \label{fig:ASGD_Ex}
 \end{center}
\end{figure}


\begin{figure}
 \begin{center}
  \includegraphics[scale=0.65]{../Graphics/ASGD_UML.pdf}
  \caption{Chart flow of ASGD algorithm. Diffusing a walker is done as described in Figure \ref{fig:diffFlowChart}. Updating the walkers involves recalculating any values affected by updating the minimum. The step is calculated by Eq.~(\ref{eq:ASGD_delta_i}). In the case of QMC, the gradient is sampled by Eq.~(\ref{eq:varParGrad}).}
  \label{fig:ASGD_flow}
 \end{center}
\end{figure}
\clearpage


\section{Variational Monte-Carlo}
\label{sec:VMC}

As briefly mentioned in the Section \ref{sec:statingDiff}, neglecting the branching term, i.e.~setting $G_\mathrm{B}=1$, corresponds to a method called Variational Monte-Carlo (VMC). The name comes from the fact that the method is is variational, that is, it supplies an upper bound to the exact ground state energy. The better the trial wave function is, the closer the VMC energy is to the exact ground state energy.

The converged state of the Markov chain in VMC is controlled by the Metropolis test, and will thus equal the trial wave function squared. From the flow chart of the VMC algorithm in Figure \ref{fig:VMCchart}, it is clear that VMC corresponds to a standard Monte-Carlo integration of the local energy sampled using a distribution equal to the trial wave function squared.

\subsection{Motivating the use of Diffusion Theory}

An important question to answer is why e.g.~the Langevin equation is so important if the result is simply an expectation value. Statistics states that \textit{any} distribution may be used when calculating an expectation value. Why bother with a trial wave function, thermalization, and so on? 

The reason is simple, yet not obvious. The quantity of interest, the local energy, \textit{depends on the trial wave function}. This is demonstrated in the following expression:

\begin{eqnarray}
 E_\mathrm{VMC} &=& \int P(\mathbf{r}) \frac{1}{\PT}\OP{H}\PT\mathrm{d}\mathbf{r} \nonumber\\
                   &\simeq& \frac{1}{n}\sum_{i=1}^n \frac{1}{\Psi_T(\mbf{r}_i)}\OP{H}\Psi_T(\mbf{r}_i), \label{eq:VMCrandomDistE}
\end{eqnarray}

where the points $\mbf{r}_i$ are drawn from the distribution $P(\mathbf{r})$.

Equation (\ref{eq:VMCrandomDistE}) implies that the evaluation of the local energy in an arbitrary distribution $P(\mathbf{r})$ is \textit{undefined} at the zeros of $\PT$. In other words, it is not guaranteed that $P(\mathbf{r})$ does not generate a point $\mathbf{r}_m$ in such a way that $\Psi_T(\mbf{r}_m) = 0$. 

However, if the distribution is chosen as $P(\mathbf{r})=|\PT|^2$, the probability of sampling a point where the local energy is undefined equals zero. This comes as a consequence of the following relation

\begin{equation}
 \Psi_T(\mathbf{r}_m) = 0 \quad\Longrightarrow\quad P(\mathbf{r}_m) = 0
\end{equation}

In other words, the more undefined the energy is at a point, the less probable the point is. This hidden detail is what Quantum Monte-Carlo safely takes care of that standard Monte-Carlo does not. 

\begin{figure}
 \begin{center}
  \includegraphics[scale=0.65]{../Graphics/VMCUML.pdf}
  \caption{Chart flow of the Variational Monte-Carlo algorithm. The second step, \textit{Diffuse Walker}, is the process described in Figure \ref{fig:diffFlowChart}. Energies are sampled as described in Section \ref{sec:calcExpVals}. The thermalization is set to a fixed number of cycles. }
  \label{fig:VMCchart}
 \end{center}
\end{figure}
\clearpage

\subsection{Implementation}

Beyond a given point, VMC does not benefit much from an increase of samples. It is much more important that the system is properly thermalized, than using several walkers or many cycles. It is therefore sufficient to use a single walker per VMC simulation.

The single walker is initialized in a normal distributed manner, and released to diffuse according to the process in Figure \ref{fig:diffFlowChart}. After accumulating energies, the final energy is calculated as the mean of these. The process is described in Figure \ref{fig:VMCchart}.

For more details regarding the specific implementation, see the code in Ref. \cite{libBorealisCode}.

\subsection{Limitations}

The only limitation in VMC is the choice of the trial wave function. This makes VMC extremely robust; it will \textit{always} produce a result. As the overlap $C_0$ from Eq.~(\ref{eq:schrodGeneralSolution2}) approach unity, the VMC energy approaches the exact ground state energy as a monotone decreasing function. Figure \ref{fig:VMC_wfcomp} demonstrates this effect. As more optimizations are added to the trial wave function, the lower the VMC energy gets.

\begin{figure}
 \begin{center}
  \includegraphics[scale=0.65]{../Graphics/WFComp.png}
  \caption{Comparison of the VMC energy using different trial wave functions. The DMC energy is believed to be very close to the exact ground state. It is apparent that adding a variational parameter to the trial wave function lowers the energy substantially, however, when adding the Jastrow factor (denoted \textit{Optimal}), described in Section \ref{sec:ChoiceTrialWF}, the VMC energy gets very close to the ``exact'' answer. A lower energy means a better energy when dealing with variational methods. In this example, a 12-particle quantum dot with unit frequency is used.}
  \label{fig:VMC_wfcomp}
 \end{center}
\end{figure}

\section{Diffusion Monte-Carlo}
\label{sec:DMC}

Applying the full diffusion framework introduced in Sections \ref{sec:statingDiff} and \ref{sec:solvingDiff} results in a method known as Diffusion Monte-Carlo (DMC)\footnote{In literature, DMC is also known as \textit{Projection Monte-Carlo}, for reasons described in Section \ref{sec:statingDiff}.}. Diffusion Monte-Carlo results are often referred to as \textit{exact}, in the sense that DMC is overall one of the most precise many-body methods available. However, just as any many-body method, DMC also has its limitations. These will be discussed in Section \ref{sec:DMClimitations}.

Where other many-body methods run into the \textit{curse of dimensionality}, that is, the CPU-time scales very bad with increasing number of particles, DMC with its position basis Quantum Monte-Carlo formalism does not. With DMC, it is simply a matter of evaluating a more complicated trial wave function, or simulating for a longer period of cycles, in order to reach convergence to the believed ``exact'' ground state in a satisfactory way.

\subsection{Implementation}

Branching is a major part of the DMC algorithm. Diffusion Monte-Carlo uses a large ensemble of walkers to generate enormous amounts of statistics. These walkers are initialized using a VMC calculation, i.e.~the walkers are initially distributed according to the trial wave function squared. 

There are three layers of loops in the DMC method implemented in this thesis, two of which are obvious: The time-step - and walker loops. However, introducing a third \textit{block loop} within the walker loop boosts the convergence dramatically. For each walker, this loop continues until the walker is either dead ($G_B = 0$), or has diffused $n_b$ times. Using this method, ``good'' walkers will have multiple offspring pr cycle, while ``bad'' walkers will rarely survive the block loop. Perfect walkers will supply a ton of statistics as they surf through all the loops without branching ($G_B \sim 1$).

A flow chart of the DMC algorithm is given in Figure \ref{fig:DMCchart}. Comparing it the the corresponding figure for VMC, it is apparent that DMC is by far more complicated. 

\subsection{Sampling the Energy}

As mentioned in Section \ref{sec:statingDiff}, the role of the branching Green's function is to distribute the correct weights to each walker. Each walker's contribution to the cumulative energy sampling should thus be weighed according to the value of the branching Green's function. Let $E_k$ denote the cumulative energy for time-step $\tau = k\delta\tau$, $n_w$ be the number of walkers in the system at time-step $k$, $\tilde n_{b,i}$ be the number of blocks walker $i$ survives, and let $W_i(\mbf{r}, \tau)$ represent walker $i$. The relation is then

\begin{equation}
 E_k = \frac{1}{n_w}\sum_{i=1}^{n_w} \frac{1}{\tilde n_{b,i}}\sum_{l=1}^{\tilde n_{b,i}} G_\mathrm{B}\Big(W_i(\mbf{r}, \tau_k + l\delta\tau)\Big)E_L\Big(W_i(\mbf{r}, \tau_k + l\delta\tau)\Big). \label{eq:DMC_Ek}
\end{equation}

As required, setting $G_B = n_w = n_b = 1$ reproduces the VMC expression. 

The new trial energy from Eq.~(\ref{eq:firstTrialEnergyIntro}) is set equal to the previous cycle's average energy, that is  

\begin{equation}
 E_T = E_k.
\end{equation}

The DMC energy is updated each cycle to be the trailing average of the trial energies:

\cfbox{2.5cm-10pt}{
\begin{equation}
 E_\mathrm{DMC} = \overline{E_T} = \frac{1}{n}\sum_{k=1}^n E_k.
\end{equation}
}


\subsection{Limitations}
\label{sec:DMClimitations}

By introducing the branching term, DMC is a far less robust method compared to VMC. Action must be taken in order to stabilize the iterations through tuning of parameters such as population size, time-step, block size, etc. This is the disadvantage of DMC compared to other many-body methods such as Coupled Cluster \cite{Hirth}, which is far more automatic.

\subsubsection{Time-step errors}

The error introduced by the short time approximation in Eq.~(\ref{eq:shortTimeApprox}) goes as $\mathcal{O}(\delta\tau^2)$. In addition, there is a second error related to the time-step, arising from the fact that not all steps are accepted by the Metropolis algorithm. This introduces a effective reduction in the time-step, and is countered by scaling the time-step with the acceptance ratio upon calculating $G_B$ \cite{abInitioMC}. However, DMC is rarely used without importance sampling, which, due to the quantum force, has an acceptance ratio very close to one. It is therefore common to ignore this problem, as its effect on the final result is minimal.

\subsubsection{Selecting the time-step}

Studying the branching Green's function in equation \ref{eq:branchFP} in more detail reveals that it's magnitude increases exponentially with the spread of the energies $\Delta E$, that is

\begin{equation}
G_B \propto \exp{\left(\Delta E\delta\tau\right)}. 
\end{equation}

As will be shown in Section \ref{sec:varAndSTD}, the spread in energy samples are higher the worse of an approximation to the ground state the trial wave function is. In addition, the magnitude of the spread scales with the magnitude of the energy. 

Setting an upper bound to the branching function might seem like a good idea, however, each time a walker is denied its replicas, an uncontrollable error is introduced in the distribution.

The solution is to balance out the increase in $\Delta E$ by lowering the time-step accordingly. That is

\begin{equation}
 \delta\tau \propto \frac{1}{\Delta E}.
\end{equation}

However, having too low a time-step will hinder DMC from evolving walkers efficiently, especially if the positional span of the distribution is large. In other words, a balance must be found. An indication of whether the time-step was chosen too low or not is obtained by looking at the resulting DMC density. If the density is spiky and disorganized, the time-step was too low. 

Another source of error is due to the \textit{fixed node approximation}. This approximation will be covered in the next section.

\begin{figure}[ht]
 \begin{center}
  \includegraphics[scale=0.65]{../Graphics/DMCUML.pdf}
  \caption{Chart flow of the Diffusion Monte-Carlo algorithm. The variable \textit{i} represents the currently moved walker. The second step, \textit{Diffuse and Branch Walker}, is the process described in Figure \ref{fig:diffFlowChart} in combination with the branching from Figure \ref{fig:branching}. Energies are sampled as in Eq.~(\ref{eq:DMC_Ek}). Thermalization is set to a fixed number of cycles.}
  \label{fig:DMCchart}
 \end{center}
\end{figure}
\clearpage

\subsection{Fixed node approximation}

Looking at Eq.~(\ref{eq:BosonicWFExplicit}), it is apparent that by choosing positive phases for the single-particle wave functions, the bosonic many-body wave function is exclusively positive. For fermions however, the sign change upon interchanging two particles introduces the possibility that the wave function will have both negative and positive regions, independent of the choice of phases in the single-particle wave functions.

As DMC iterates, the density of walkers at a given time, $P(\mathbf{r}, \tau)$, represents the projected wave function from Eq.~(\ref{eq:schrodGeneralSolution2}) multiplied by the trial wave function. 

\begin{equation}
 P(\mathbf{r}, \tau) = \Ptau\PT.
\end{equation}

This relationship is described in high detail in Section \ref{sec:anisFokker}.

Applying the projector operator to the distribution yields

\begin{equation}
  \lim_{\tau\to\infty} P(\mathbf{r}, \tau) = \braket{\Phi_0}{\Phi_T}\Phi_0(\mathbf{r})\Psi_T(\mathbf{r}),
\end{equation}

which, if interpreted as a density, should always be greater than zero. In the case of fermions, this is not guaranteed, as
the node structure of the exact ground state and the trial wave function will generally be different.  

To avoid this anomaly in the density, $\Ptau$ and $\PT$ have to change sign simultaneously\footnote{It should be mentioned that more sophisticated methods exist for dealing with the sign problem, some of which splits the distribution of walkers into a negative and a positive regions, however, due to the position space being infinite, this requires an enormous amount of walkers to succeed.}. The brute force way of solving this problem is to \textit{fix} the nodes by rejecting a walker's step if the trial wave function changes sign:

\begin{equation}
\frac{\Psi_T(\mathbf{r}_i)}{\Psi_T(\mathbf{r}_j)} < 0 \quad\Longrightarrow\quad A(i\,\rightarrow\,j) = 0,
\end{equation}

where $A(i\,\rightarrow\,j)$ is the probability of accepting the move, as described in Section \ref{sec:MetroMain}. An illustrative example is given in Figure \ref{fig:fixxednode}.

\begin{figure}
 \begin{center}
  \includegraphics[scale=0.3]{../Graphics/fixxednode.pdf}
  \caption{A one-dimensional illustration of the fixed node approximation. The dotted line represents the exact ground state $\Psi_0(x)$. The distribution of walkers after $n$ Monte-Carlo cycles is represented by $\Phi(x, n\delta\tau)$. The trial wave function $\Psi_T(x)$ shares nodes with $\Phi(x, n\delta\tau)$, making it impossible for $\Phi(x, n\delta\tau)$ to match $\Psi_0(x)$.}
  \label{fig:fixxednode}
 \end{center}
\end{figure}


\section{Estimating One-body Densities}
\label{sec:OBD}

The one-body density is defined as

\begin{equation}
 \rho(  \mathbf{r}_1) = \iint\limits_{  \mathbf{r}_2   \mathbf{r}_3}...\int\limits_{  \mathbf{r}_N} \left|\Phi(  \mathbf{r}_1   \mathbf{r}_2 ...   \mathbf{r}_N)\right|^2\mathrm{d}  \mathbf{r}_2...\mathrm{d}  \mathbf{r}_N.
\end{equation}

Unlike the distribution $|\Phi(\mathbf{r})|^2$, which describes the distribution of any of the particles in the system, the one-body density $\rho(\mathbf{r}_1)$ describes the simultaneous distribution of every particle in the system, that is, $\rho(\mathbf{r}_1)\mathrm{d}\mathbf{r}_1$ represents the probability of finding \textit{any} of the system's $N$ particles within the volume element $\mathrm{d}\mathbf{r}_1$. Due to the indistinguishable nature of the particles, the fact that the first coordinate is chosen is purely conventional; any of the $N$ coordinates contain information about all the particles. For the same reason, the one-body density should be normalized to the number of particles, and not to unity.   

In a Monte-Carlo simulation, estimating the one-body density is done by collecting snapshots of the walkers' positions. These snapshots serve as samples to a histogram where each set of Cartesian coordinates give rise to one histogram-count.

\subsection{Estimating the Exact Ground State Density}

It was mentioned in the section on VMC that the final state of convergence was to have to walkers span the trial wave function. This implies that the one-body density of the trial wave function, called the \textit{variational density}, can be calculated using positional data generated from VMC.

The challenge lies in estimating the one-body density of the exact wave function given a set of DMC data. As described in Section \ref{sec:anisFokker}, the distribution of walkers span the \textit{mixed density} $f(\mathbf{r}, \tau) = \Ptau\PT$, which does not correspond to the ground state distribution unless the trial wave function is indeed the exact ground state. Hence a histogram of the DMC data does not suffice when it comes to presenting the exact wave function.

This implies the need of a method for transforming the one-body density of $f(\mathbf{r}, \tau)$ into the \textit{pure density} $|\Ptau|^2$. To achieve this, the following relation is needed \cite{abInitioMC}

\begin{align}
 \langle A \rangle_0 = \frac{\bra{\Phi_0}\OP{A}\ket{\Phi_0}}{\braket{\Phi_0}{\Phi_0}} &\simeq  2\frac{\bra{\Phi_0}\OP{A}\ket{\Psi_T}}{\braket{\Phi_0}{\Psi_T}} -  \frac{\bra{\Psi_T}\OP{A}\ket{\Psi_T}}{\braket{\Psi_T}{\Psi_T}} + \mathcal{O}(\Delta^2)\notag\\
  &= 2\langle A \rangle_\mathrm{DMC} - \langle A \rangle_\mathrm{VMC}  + \mathcal{O}(\Delta^2), \label{eq:PureEstimRelat}
\end{align}

where $\Delta \equiv \PT - \Ptau$. 

Expressed in terms of \textit{density operators}, the expectation values for the different methods are \cite{leinaas}

\newcommand{\tr}{\mathrm{tr}}

\begin{align*}
 \langle A \rangle_0 &= \tr(\OP{\rho}_0\OP{A}) \\
 \langle A \rangle_\mathrm{VMC} &= \tr(\OP{\rho}_\mathrm{VMC}\OP{A}) \\
 \langle A \rangle_\mathrm{DMC} &= \tr(\OP{\rho}_\mathrm{DMC}\OP{A}) 
 \end{align*}

where $\tr$ denotes the \textit{trace}, i.e.~the sum of all eigenvalues. Inserting these equations into Eq.~(\ref{eq:PureEstimRelat}) yield

\begin{align}
 \tr(\OP{\rho}_0\OP{A}) &\simeq 2\tr(\OP{\rho}_\mathrm{DMC}\OP{A}) -  \tr(\OP{\rho}_\mathrm{VMC}\OP{A}) + \mathcal{O}(\Delta^2) \notag\\
  &\simeq \tr\left(\left(2\OP{\rho}_\mathrm{DMC} - \OP{\rho}_\mathrm{VMC}\right)\OP{A}\right) + \mathcal{O}(\Delta^2),
\end{align}

which leads to the conclusion that the mixed density can be transformed in the following manner:

\begin{equation}
 \OP{\rho}_0 \simeq 2\OP{\rho}_\mathrm{DMC} - \OP{\rho}_\mathrm{VMC} .\label{eq:densityTransform}
\end{equation}

It is clear that if this relation holds for regular densities, it will hold for one-body densities as well. In other words, the resulting densities from DMC can be combined with the corresponding one from VMC to produce the pure density.

\subsection{Radial Densities}

Integrating out every degree of freedom except one radial coordinate from the density results in the radial one-body density times the radius (squared for three dimensions). In other words

\begin{align}
 I_\mathrm{3D} &= \iint \rho (\mathbf{r}_1, \theta_1, \phi_1)r_1^2\sin\theta_1\mathrm{d}\theta_1\mathrm{d}\phi_1 \notag\\
   &\propto r_1^2\rho(\mathbf{r}_1), \label{eq:averagedRadialOBD_3D} \\
 I_\mathrm{2D} &= \int \rho (\mathbf{r}_1, \phi_1)r_1\mathrm{d}\phi_1 \notag\\
   &\propto r_1\rho(\mathbf{r}_1). \label{eq:averagedRadialOBD_2D}
\end{align}

In practice, these integrals are calculated by creating histograms $H(r)$ of all sampled radii. Transforming the histograms into radial one-body densities $\rho(r_1)$ are according to Eq.~(\ref{eq:averagedRadialOBD_3D}) and Eq.~(\ref{eq:averagedRadialOBD_2D}) done in the following manner

\begin{equation}
 \rho(\mathbf{r}_1) = \frac{H(\mathbf{r}_1)}{r_1^{(d-1)}},\label{eq:radial_OBD}
\end{equation}

where $d$ denotes the number of dimensions. An example presenting two radial one-body densities is given in Figure \ref{fig:OBD_ex}. Notice, however, that the radial density for certain systems such as atoms needs to be scaled with $r$ or $r^2$ in order to reveal the interesting shapes. 

\begin{figure}
 \begin{center}
  \subfigure{\includegraphics[scale=0.35]{../Graphics/OBD_rad_ex_12pw01.png}}
  \subfigure{\includegraphics[scale=0.3816]{../Graphics/OBD/OBD_Atoms/2D/Beryllium.png}}
  \caption{Two examples of radial one-body densities for VMC, DMC, and the pure density from Eq.~(\ref{eq:densityTransform}). On the left: A 12-particle two-dimensional quantum dot with frequency $\omega=0.1$. The density diverges close to zero due to a ``$\frac{0}{0}$'' expression (see Eq.~(\ref{eq:radial_OBD})). On the right: Unscaled radial density for the beryllium atom, i.e.~$r_1^2\rho(\mathbf{r}_1)$. The densities will be discussed in the result section.}
  \label{fig:OBD_ex}
 \end{center}
\end{figure}


\section{Estimating the Statistical Error}

As with any statistical result, the statistical errors need to be supplied in order for the result to be considered useful. Systematic errors, that is, errors introduced due to limitations in the model, is discussed in each method's respective section, and is not be related to the statistical error, that is, the exact solution does not necessarily have to be within the error. This is only true if there are no systematic errors.

Statistical errors can be estimated using several methods, some of which are \textit{naive} in the sense that they assume the dataset to be completely \textit{uncorrelated}, i.e.~independent of each other.

\subsection{The Variance and Standard Deviates}
\label{sec:varAndSTD}

Given a set of samples, e.g.~local energies, their \textit{variance} is a measure of their spread from the true mean value. The definition of variance reads

\begin{eqnarray}
\label{eq:variance}
\Var(E) &\equiv& \Exp{(E-\Exp{E})^2} \nonumber\\
        &=& \Exp{E^2} - 2\underbrace{\Exp{E\Exp{E}}}_{\Exp{E}\Exp{E}} + \Exp{E}^2 \nonumber\\
        &=& \Exp{E^2} - \Exp{E}^2. \\
\end{eqnarray}

A problem with this definition is that the exact mean $\Exp{E}$ needs to be known. In a Monte-Carlo simulation, the resulting average $\overline{E}$ is an approximation to the exact mean. Thus the following approximation has to be done:

\begin{eqnarray}
  \Var(E) &\simeq& \overline{E^2} - \overline{E}^2.
\end{eqnarray}

In the case of having the exact wave function, i.e~$\ket{\Psi_T} = \ket{\Psi_0}$, the variance becomes zero:

\begin{eqnarray*}
\label{eq:varianceZeroExact}
\Var(E)_\mathrm{Exact} &=& \bra{\Psi_0}\OP{H}^2\ket{\Psi_0} -  \bra{\Psi_0}\OP{H}\ket{\Psi_0}^2 \\
		        &=& E_0^2 - (E_0)^2 \\
		        &=& 0
\end{eqnarray*}

The variance is in other words an excellent measure of how close to the exact wave function the trial wave function is, hence the variance minimum is sometimes used to obtain optimal variational parameters discussed in Section \ref{sec:selectingOptVarPar}. 

A common misconception is that the numerical value of the variance can be used to compare properties of \textit{different} systems. For instance, if system $A$ has variance equal to half of system $B$'s, one could easily conclude that system $A$ has the best fitting trial wave function. However, this is not generally true. The variance has unit energy squared (in the case of local energies), and will thus scale with the magnitude of the energy. One can only safely use the variance as a direct measure locally in each specific system, e.g.~in simulations of the beryllium atom.

Another misconception is that the variance is a direct numerical measure of the error. This can in no way be true given that the units mismatch. The \textit{standard deviation}, $\sigma$, is the square root of the variance, that is

\begin{equation}
\label{eq:stdNaive}
 \sigma^2(x) = \Var(x),
\end{equation}


and has a unit equal to that of the measured value. It is therefore related to the \textit{spread} in the sampled value; zero deviation implies perfect samples, while increasing deviation means increasing spread and statistical uncertainty. The standard deviation is in other words a useful quantity when it comes to calculating the error, i.e.~the expected deviation from the exact mean $\Exp{E}$.

\subsection{The Covariance and correlated samples}

It was briefly mentioned in the introduction that certain error estimation techniques are too naive in the sense that they do not account for samples being correlated. Two samples, $x$ and $y$, are said to be correlated if their \textit{covariance}, $\Cov(x, y)$, is non-zero. The covariance is defined the following way:

\begin{eqnarray}
\label{eq:covariance}
 \Cov(x, y) &\equiv& \Exp{(x - \Exp{x})(y - \Exp{y})} \nonumber\\
            &=& \Exp{xy - x\Exp{y} - \Exp{x}y + \Exp{x}\Exp{y}} \nonumber\\
            &=& \Exp{xy} - \Exp{x\Exp{y}} \underbrace{-\Exp{y\Exp{x}} + \Exp{\Exp{x}\Exp{y}}}_{0} \nonumber\\
            &=& \Exp{xy} - \Exp{x}\Exp{y}.
\end{eqnarray}

Using this definition, whether or not the samples are correlated boils down to whether or not $\Exp{xy} = \Exp{x}\Exp{y}$. Notice that the variance is the diagonal elements of the covariance matrix, i.e~$\Cov(x,x) = \Var(x)$.

The consequence of ignoring the correlations is an error estimate which is generally smaller than the true error; correlated samplings are more clustered, i.e.~less spread, due to previous samples' influence on the value of the current sample\footnote{Samples in QMC are obviously correlated due to the nature of the Langevin equation (difference equation).}. Denoting the true standard deviation as $\sigma_c$, the above discussion can be distilled to

\begin{equation}
 \label{eq:trueVsNaiveSTD}
 \sigma_c(x) \ge \sigma(x),
\end{equation}

where $\sigma(x)$ is the deviation from Eq.~(\ref{eq:stdNaive}). 


\subsection{The Deviate from the Exact Mean}

There is an important difference between the deviate from the exact mean, and the deviate of a single sample from its combined mean. In other words:

\begin{equation}
 \sigma(\overline{x}) \ne \sigma(x).
\end{equation}

Imagine doing a number of simulations, each resulting in a unique $\overline{x}$. The quantity of interest is not the error of single samples, but the error in the calculated mean. Let $m$ denote the outcome of a single Monte-Carlo calculation. That is

\begin{eqnarray}
 m = \frac{1}{n}\sum_{i=1}^n x_i. \label{eq:meanx}
 \end{eqnarray}

 The error in the mean is obtained by calculating the standard deviation in $m$. That is, calculating
 
 \begin{eqnarray}
 \sigma^2(m) &=& \Exp{m^2} - \Exp{m}^2. \label{eq:sigma_m}
\end{eqnarray}

Combining the two above equations yield

\begin{eqnarray}
\label{eq:realErrorCovariance1}
  \sigma^2(m) &=& \Exp{\frac{1}{n^2}\left[\sum_{i=1}^nx_i\right]^2} - \Exp{\frac{1}{n}\sum_{i=1}^n x_i}^2 \nonumber\\
              &=& \frac{1}{n^2}\left( \Exp{\sum_{i=1}^n x_i\sum_{j=1}^n x_j} - \Exp{\sum_{i=1}^n x_i}\Exp{\sum_{j=1}^n x_j}  \right) \nonumber\\
              &=& \frac{1}{n^2}\sum_{i,j=1}^n \Exp{x_ix_j} - \Exp{x_i}\Exp{x_j} \nonumber\\
              &=& \frac{1}{n^2}\sum_{i,j=1}^n \Cov(x_i, x_j).
\end{eqnarray}

This result is important; the true error is given in terms of the covariance, and is, as discussed previously, only equal to the sample variance if the samples are uncorrelated. Going back to the definition of covariance in Eq.~(\ref{eq:covariance}), it is apparent that in order to calculate the covariance as in Eq.~(\ref{eq:realErrorCovariance1}), the true mean $\Exp{x_i}$ needs to be known. Using $m$ as an  approximation to the exact mean yields   

\begin{eqnarray}
 \Cov(x_i, x_j) &=& \Exp{(x_i - \Exp{x_i})(x_j - \Exp{x_j})} \nonumber\\
                &\simeq& \Exp{(x_i - m)(x_j - m)} \nonumber\\
                &\simeq& \frac{1}{n^2}\sum_{k,l=1}^n (x_k-m)(x_l-m) \\
                &\equiv& \frac{1}{n}\Cov(x).
\end{eqnarray}

Inserting this relation into Eq.~(\ref{eq:realErrorCovariance1}) yields

\cfbox{2.7cm-8pt}{
\begin{eqnarray}
\label{eq:realErrorCovariance2}
   \sigma^2(m) &=& \frac{1}{n^2}\sum_{i,j=1}^n \Cov(x_i, x_j) \nonumber\\
               &\simeq& \frac{1}{n^2}\sum_{i,j=1}^n \frac{1}{n}\Cov(x) \nonumber\\
               &=& \frac{1}{n^3}\Cov(x)\underbrace{\sum_{i,j=1}^n}_{n^2}  \nonumber\\
               &=& \frac{1}{n} \Cov(x), \\
               \nonumber
\end{eqnarray}
}

which serves as an estimate of the full error including correlations. 

Explicitly computing the covariance is rarely done in Monte-Carlo simulations; if the sample size is large, it is extremely expensive. A variety of alternative methods to counter the correlations are available, the simplest of which is to define a \textit{correlation length}\footnote{In literature, this parameter is often referred to as the \textit{auto-correlation time}.}, $\tau$, which defines an interval at which points from the sampling sets are used for actual averaging. In other words, only the points $x_0, x_{\tau}, ..., x_{n\tau}$ are used in the calculation of the mean. In other words

\begin{equation}
 m = \frac{1}{n}\sum_{k=0}^n x_{k\cdot\tau}.
\end{equation}

This implies that $n\tau$ samples are needed in order to get the same amount of samples to the average as in Eq.~(\ref{eq:meanx}); the \textit{effective sample size} becomes $n_\mathrm{eff} = n_\mathrm{tot}/\tau$. In the cases where $\tau = 1$, the sample set is uncorrelated. For details regarding the derivations of $\tau$ based on the covariance, see Refs. \cite{flyvbjerg:461} and \cite{morten}.

\subsection{Blocking}

Introducing correlation lengths in the system solver are not an efficient option. Neither is calculating the covariance of billions of data points. However, the error is not a value vital to the simulation process, i.e.~there is no need to know the error at any stage during the sampling. This means that the error estimation can be done post process (given that the sample set is stored).

An efficient algorithm for calculating the error of correlated data is \textit{blocking}. This method is described in high detail in Ref. \cite{flyvbjerg:461}, however, details aside, the idea itself is quite intuitive: Given a set of $N$ samples from a single Monte-Carlo simulation, imagine dividing the dataset into \textit{blocks} of $n$ samples, that is, into blocks of size $n_b=N/n$. The error in each block  $\sigma_n$ calculated using Eq.~(\ref{eq:realErrorCovariance2}) will naturally increase as $n$ decrease, that is

\begin{equation}
 \sigma_n \propto \frac{1}{\sqrt{n}}.
\end{equation}

However, treating each block as an individual simulation, $n_b$ averages $m_n$ can be used to calculate the total error from Eq.~(\ref{eq:sigma_m}), that is, estimate the covariance. This is demonstrated in the following expression

\begin{eqnarray}
  \overline{m_n^r} &\equiv& \frac{1}{n_b}\sum_{k=1}^{n_b} m_k^r, \\
\nonumber\\
  \sigma^2(m) &=& \Exp{m^2} - \Exp{m}^2 \nonumber\\
              &\simeq& \overline{m_n^2} - (\overline{m_n})^2. \label{eq:blockingError}
\end{eqnarray}

The approximation in Eq.~(\ref{eq:blockingError}) should hold for a range of different block sizes, however, just as there is no a priori way of telling the correlation length, there is no a priori way of telling how many blocks is needed. However, what is known, is that if the system is correlated, there should be a range of different block sizes which fulfills Eq.~(\ref{eq:blockingError}) to reasonable precision. 

The result of a blocking analysis is therefore a series of ($n$, $\sigma(m_n)$) pairs which can be plotted. The plot should in light of previous arguments result in a increasing curve which stabilizes over a certain span of block sizes. This plateau will then serve as a reasonable approximation to the covariance, that is, the true error. See Figure \ref{FIG:BlockingExamples} for a demonstration of blocking plots.

\begin{figure}
 \begin{center}
  \subfigure{\includegraphics[scale=0.35]{../Graphics/BlockingExampleUncorr.png}}
  \subfigure{\includegraphics[scale=0.35]{../Graphics/BlockingExampleCorr.png}} 
  \caption{Left hand side: Blocking result of (approximately) uncorrelated data generated from a uniform Monte-Carlo integration of $\int _1^2 2x\mathrm{d}x$ resulting in $3.00003$ (exact is $3.0$). This is in excellent agreement with the magnitude of the error $\sim 9\cdot 10^{-5}$. There is no sign of a plateau, which implies fairly uncorrelated data (the span of the spread is small and apparently random). Right hand side: Blocking result of a DMC simulation of a 6-particle two-dimensional quantum dot with frequency $\omega=0.1$. The plateau is strongly present, implying correlated data. The resulting total error is  $\sim 4.5\cdot 10^{-5}$.}
  \label{FIG:BlockingExamples}
 \end{center}
\end{figure}


\subsection{Variance Estimators}

The standard intuitive variance estimator

\begin{equation}
\label{eq:varBias}
 \sigma^2(x) \simeq \frac{1}{n}\sum_{i=1}^n (x_i - \overline{x})^2 = \left(\frac{1}{n}\sum_{i=1}^n x_i^2\right) - \overline{x}^2,
\end{equation}

is just an example of a variance estimator. A more precise estimator is 

\begin{equation}
\label{eq:varUnbias}
 \sigma^2(x) \simeq \frac{1}{n-1}\sum_{i=1}^n (x_i - \overline{x})^2 = \left(\frac{1}{n-1}\sum_{i=1}^n x_i^2\right) - \frac{n}{n-1}\overline{x}^2,
\end{equation}

which is only noticeably different from Eq.~(\ref{eq:varBias}) when the sample size gets small, as it does in blocking analysis. It is therefore standard to use Eq.~(\ref{eq:varUnbias}) for blocking errors.


