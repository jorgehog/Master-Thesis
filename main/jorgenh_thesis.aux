\relax 
\ifx\hyper@anchor\@undefined
\global \let \oldcontentsline\contentsline
\gdef \contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global \let \oldnewlabel\newlabel
\gdef \newlabel#1#2{\newlabelxx{#1}#2}
\gdef \newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\let \contentsline\oldcontentsline
\let \newlabel\oldnewlabel}
\else
\global \let \hyper@last\relax 
\fi

\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{verdensBesteArtikkel}
\citation{Hirth}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{7}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{H_He_exact,ExactMolecules,AtomsExact,KryptonExact}
\citation{forcesQMC}
\citation{Hirth}
\citation{Olsen}
\citation{libBorealisCode}
\citation{MD1,MD2}
\@writefile{toc}{\contentsline {subsubsection}{The structure of the thesis}{8}{chapter.1}}
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Theory}{9}{part.1}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Quantum Monte-Carlo}{11}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:QMC}{{2}{11}{Quantum Monte-Carlo\relax }{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Modelling Diffusion}{11}{section.2.1}}
\citation{griffiths}
\citation{Shavitt}
\citation{Sigve}
\citation{QMCDIFF}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}Stating the Schr\IeC {\"o}dinger Equation as a Diffusion Problem}{12}{subsection.2.1.1}}
\newlabel{sec:statingDiff}{{2.1.1}{12}{Stating the Schrödinger Equation as a Diffusion Problem\relax }{subsection.2.1.1}{}}
\newlabel{eq:schrodTimeIndie}{{2.2}{12}{Stating the Schrödinger Equation as a Diffusion Problem\relax }{equation.2.1.2}{}}
\newlabel{eq:schrodGeneralSolution}{{2.3}{12}{Stating the Schrödinger Equation as a Diffusion Problem\relax }{equation.2.1.3}{}}
\newlabel{eq:TimeEvolOp}{{2.4}{12}{Stating the Schrödinger Equation as a Diffusion Problem\relax }{equation.2.1.4}{}}
\newlabel{eq:projOPonTrial}{{2.5}{13}{Stating the Schrödinger Equation as a Diffusion Problem\relax }{equation.2.1.5}{}}
\newlabel{eq:schrodGeneralSolution2}{{2.6}{13}{Stating the Schrödinger Equation as a Diffusion Problem\relax }{equation.2.1.6}{}}
\newlabel{eq:ExactProjection}{{2.7}{13}{Stating the Schrödinger Equation as a Diffusion Problem\relax }{equation.2.1.7}{}}
\citation{abInitioMC}
\newlabel{eq:QMC_GF_EQ}{{2.12}{14}{Stating the Schrödinger Equation as a Diffusion Problem\relax }{equation.2.1.12}{}}
\newlabel{eq:firstTrialEnergyIntro}{{2.13}{14}{Stating the Schrödinger Equation as a Diffusion Problem\relax }{equation.2.1.13}{}}
\newlabel{eq:shortTimeApprox}{{2.14}{14}{Stating the Schrödinger Equation as a Diffusion Problem\relax }{equation.2.1.14}{}}
\newlabel{eq:GDiff}{{2.15}{14}{Stating the Schrödinger Equation as a Diffusion Problem\relax }{equation.2.1.15}{}}
\newlabel{eq:GB}{{2.16}{14}{Stating the Schrödinger Equation as a Diffusion Problem\relax }{equation.2.1.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Solving the Diffusion Problem}{14}{section.2.2}}
\newlabel{sec:solvingDiff}{{2.2}{14}{Solving the Diffusion Problem\relax }{section.2.2}{}}
\citation{abInitioMC}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Isotropic Diffusion}{15}{subsection.2.2.1}}
\newlabel{Eq:diffusionSimple}{{2.17}{15}{Isotropic Diffusion\relax }{equation.2.2.17}{}}
\newlabel{eq:GF_iso}{{2.18}{15}{Isotropic Diffusion\relax }{equation.2.2.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{The Langevin Equation for isotropic diffusion}{15}{equation.2.2.18}}
\newlabel{eq:langevinSolSimple}{{2.19}{15}{The Langevin Equation for isotropic diffusion\relax }{equation.2.2.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Anisotropic Diffusion and the Fokker-Planck equation}{15}{subsection.2.2.2}}
\newlabel{sec:anisFokker}{{2.2.2}{15}{Anisotropic Diffusion and the Fokker-Planck equation\relax }{subsection.2.2.2}{}}
\citation{abInitioMC}
\newlabel{Eq:fokkerPlanck}{{2.20}{16}{Anisotropic Diffusion and the Fokker-Planck equation\relax }{equation.2.2.20}{}}
\newlabel{eq:GF_FP}{{2.22}{16}{Anisotropic Diffusion and the Fokker-Planck equation\relax }{equation.2.2.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{The Langevin Equation for the Fokker-Planck equation}{16}{equation.2.2.22}}
\citation{Gardiner:2004bk,risken1989fpe,langevin}
\newlabel{eq:langevinSolFP}{{2.24}{17}{The Langevin Equation for the Fokker-Planck equation\relax }{equation.2.2.24}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Connecting Anisotropic - and Isotropic Diffusion Models}{17}{subsection.2.2.3}}
\newlabel{sec:ConnectAnisIs}{{2.2.3}{17}{Connecting Anisotropic - and Isotropic Diffusion Models\relax }{subsection.2.2.3}{}}
\newlabel{eq:impSamplRaw}{{2.25}{17}{Connecting Anisotropic - and Isotropic Diffusion Models\relax }{equation.2.2.25}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Diffusive Equilibrium Constraints}{19}{section.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Detailed Balance}{19}{subsection.2.3.1}}
\citation{robertcasella}
\newlabel{eq:DetailedBalance}{{2.29}{20}{Detailed Balance\relax }{equation.2.3.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Ergodicity}{20}{subsection.2.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}The Metropolis Algorithm}{20}{section.2.4}}
\newlabel{sec:MetroMain}{{2.4}{20}{The Metropolis Algorithm\relax }{section.2.4}{}}
\newlabel{eq:metro1}{{2.30}{20}{The Metropolis Algorithm\relax }{equation.2.4.30}{}}
\newlabel{eq:metro2}{{2.31}{20}{The Metropolis Algorithm\relax }{equation.2.4.31}{}}
\citation{robertcasella}
\citation{morten}
\newlabel{eq:MetroGeneralGreen}{{2.32}{21}{The Metropolis Algorithm\relax }{equation.2.4.32}{}}
\newlabel{eq:Metropolis_standard}{{2.34}{21}{The Metropolis Algorithm\relax }{equation.2.4.34}{}}
\newlabel{eq:MetropolisHastings}{{2.36}{21}{The Metropolis Algorithm\relax }{equation.2.4.35}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Flow chart describing the process of iterating a walker through a single time-step, that is, simulation the application of the Green's function from Eq.~(\ref  {eq:GDiff}) using the Metropolis algorithm. New positions are suggested according to the chosen diffusion model.\relax }}{22}{figure.caption.4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:diffFlowChart}{{2.1}{22}{Flow chart describing the process of iterating a walker through a single time-step, that is, simulation the application of the Green's function from Eq.~(\ref {eq:GDiff}) using the Metropolis algorithm. New positions are suggested according to the chosen diffusion model.\relax \relax }{figure.caption.4}{}}
\citation{abInitioMC}
\citation{libBorealisCode}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}The Process of Branching}{23}{section.2.5}}
\newlabel{sec:branching}{{2.5}{23}{The Process of Branching\relax }{section.2.5}{}}
\newlabel{eq:branchISO}{{2.37}{23}{The Process of Branching\relax }{equation.2.5.37}{}}
\newlabel{eq:branchFP}{{2.38}{23}{The Process of Branching\relax }{equation.2.5.37}{}}
\newlabel{eq:gbMean}{{2.39}{23}{The Process of Branching\relax }{equation.2.5.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The process of branching illustrated. The initial walker $W_i(R, \tau )$ is branched according to the rules of Section \ref  {sec:branching}. The numerical value inside the nodes represents the value of $\overline  {G}_B$ from Eq.~(\ref  {eq:gbMean}). Each horizontal dashed line represent a diffusion step, i.e.~a transition in time. Two lines exiting the same node represent identical walkers. After moving through the diffusion process, no two walkers should ever be equal, given that not all of the steps was rejected by the Metropolis test.\relax }}{24}{figure.caption.5}}
\newlabel{fig:branching}{{2.2}{24}{The process of branching illustrated. The initial walker $W_i(R, \tau )$ is branched according to the rules of Section \ref {sec:branching}. The numerical value inside the nodes represents the value of $\overline {G}_B$ from Eq.~(\ref {eq:gbMean}). Each horizontal dashed line represent a diffusion step, i.e.~a transition in time. Two lines exiting the same node represent identical walkers. After moving through the diffusion process, no two walkers should ever be equal, given that not all of the steps was rejected by the Metropolis test.\relax \relax }{figure.caption.5}{}}
\citation{griffiths,Sakurai:94,Shavitt}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}The Trial Wave Function}{25}{section.2.6}}
\newlabel{sec:trialWF}{{2.6}{25}{The Trial Wave Function\relax }{section.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Many-body Wave Functions}{25}{subsection.2.6.1}}
\newlabel{sec:manyBodyWFs}{{2.6.1}{25}{Many-body Wave Functions\relax }{subsection.2.6.1}{}}
\newlabel{eq:manyBodyExp}{{2.41}{25}{Many-body Wave Functions\relax }{equation.2.6.41}{}}
\newlabel{eq:manybodyWFexp}{{2.42}{25}{Many-body Wave Functions\relax }{equation.2.6.42}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Three different electron configurations in an shell structure making up three different $\Phi _k(\mathbf  {r})$, i.e. constituents of the many-body basis described in Eq.~(\ref  {eq:manybodyWFexp}). An electron (solid dot) is represented by e.g. the orbital $\phi _{1s}(\mathbf  {r}_1)$.\relax }}{26}{figure.caption.6}}
\newlabel{fig:AtomicOrbitals}{{2.3}{26}{Three different electron configurations in an shell structure making up three different $\Phi _k(\mathbf {r})$, i.e. constituents of the many-body basis described in Eq.~(\ref {eq:manybodyWFexp}). An electron (solid dot) is represented by e.g. the orbital $\phi _{1s}(\mathbf {r}_1)$.\relax \relax }{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Step one in detail}{27}{figure.caption.6}}
\newlabel{eq:orbitalEigenEq}{{2.46}{27}{Step one in detail\relax }{equation.2.6.46}{}}
\@writefile{toc}{\contentsline {subsubsection}{Step two in detail}{27}{equation.2.6.46}}
\citation{morten}
\newlabel{eq:SlaterDeterminantExplicit}{{2.47}{28}{Step two in detail\relax }{equation.2.6.47}{}}
\newlabel{eq:BosonicWFExplicit}{{2.48}{28}{Step two in detail\relax }{equation.2.6.47}{}}
\@writefile{toc}{\contentsline {subsubsection}{Dealing with correlations}{28}{equation.2.6.47}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}Choosing the Trial Wave Function}{28}{subsection.2.6.2}}
\newlabel{sec:ChoiceTrialWF}{{2.6.2}{28}{Choosing the Trial Wave Function\relax }{subsection.2.6.2}{}}
\citation{abInitioMC}
\citation{abInitioMC}
\citation{larseivind}
\citation{QMCPHD2008}
\newlabel{eq:firstAnzatsTWF}{{2.49}{29}{Choosing the Trial Wave Function\relax }{equation.2.6.49}{}}
\@writefile{toc}{\contentsline {subsubsection}{Explicit shapes}{29}{equation.2.6.49}}
\newlabel{eq:jastrow}{{2.51}{29}{Explicit shapes\relax }{equation.2.6.51}{}}
\citation{UmrigarMolecules}
\newlabel{eq:splitSlater}{{2.52}{30}{Explicit shapes\relax }{equation.2.6.52}{}}
\newlabel{eq:MultiDeterminantTWF}{{2.53}{30}{Explicit shapes\relax }{equation.2.6.53}{}}
\@writefile{toc}{\contentsline {subsubsection}{Limitations}{30}{equation.2.6.53}}
\@writefile{toc}{\contentsline {subsubsection}{Single-determinant trial wave functions}{30}{equation.2.6.53}}
\newlabel{eq:singleDeterminantTWF}{{2.54}{31}{Single-determinant trial wave functions\relax }{equation.2.6.54}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.3}Selecting Optimal Variational Parameters}{31}{subsection.2.6.3}}
\newlabel{sec:selectingOptVarPar}{{2.6.3}{31}{Selecting Optimal Variational Parameters\relax }{subsection.2.6.3}{}}
\newlabel{eq:varMin}{{2.55}{31}{Selecting Optimal Variational Parameters\relax }{equation.2.6.55}{}}
\citation{golub1996matrix}
\newlabel{eq:varParGrad}{{2.56}{32}{Selecting Optimal Variational Parameters\relax }{equation.2.6.56}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.4}Calculating Expectation Values}{32}{subsection.2.6.4}}
\newlabel{sec:calcExpVals}{{2.6.4}{32}{Calculating Expectation Values\relax }{subsection.2.6.4}{}}
\newlabel{eq:MeanVStrueExp}{{2.61}{33}{Calculating Expectation Values\relax }{equation.2.6.61}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.5}Normalization}{33}{subsection.2.6.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Two steps of a one dimensional Gradient Descent process. Steps are taken in the direction of the negative gradient (indicated by dotted lines).\relax }}{34}{figure.caption.7}}
\newlabel{fig:SGD}{{2.4}{34}{Two steps of a one dimensional Gradient Descent process. Steps are taken in the direction of the negative gradient (indicated by dotted lines).\relax \relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Gradient Descent Methods}{34}{section.2.7}}
\newlabel{sec:GradientDescent}{{2.7}{34}{Gradient Descent Methods\relax }{section.2.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}General Gradient Descent}{34}{subsection.2.7.1}}
\citation{ASGD_MB}
\newlabel{eq:SGD}{{2.67}{35}{General Gradient Descent\relax }{equation.2.7.67}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.2}Stochastic Gradient Descent}{35}{subsection.2.7.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.3}Adaptive Stochastic Gradient Descent}{35}{subsection.2.7.3}}
\newlabel{eq:ASGD_X_i}{{2.68}{35}{Adaptive Stochastic Gradient Descent\relax }{equation.2.7.68}{}}
\citation{ASGD}
\citation{ASGD}
\citation{ASGD}
\citation{ASGD}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces A one dimensional plot of an expectation value function. Smeared lines are representing uncertainties due to rough sampling. The direction of the local gradient (solid green line) at a point $x_i$ is not necessarily a good estimate of the actual analytic gradient (dashed red line).\relax }}{36}{figure.caption.8}}
\newlabel{fig:sSGD}{{2.5}{36}{A one dimensional plot of an expectation value function. Smeared lines are representing uncertainties due to rough sampling. The direction of the local gradient (solid green line) at a point $x_i$ is not necessarily a good estimate of the actual analytic gradient (dashed red line).\relax \relax }{figure.caption.8}{}}
\newlabel{eq:ASGD_delta_i}{{2.70}{36}{Adaptive Stochastic Gradient Descent\relax }{equation.2.7.69}{}}
\newlabel{eq:ASGD_t_i}{{2.71}{36}{Adaptive Stochastic Gradient Descent\relax }{equation.2.7.69}{}}
\newlabel{eq:ASGD_f_i}{{2.72}{36}{Adaptive Stochastic Gradient Descent\relax }{equation.2.7.69}{}}
\@writefile{toc}{\contentsline {subsubsection}{Assumptions}{36}{figure.caption.9}}
\citation{ASGD}
\citation{libBorealisCode}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Examples of $f(X_i)$ as published in Ref. \cite  {ASGD}. As $\omega \to 0$, $f(x)$ approaches a step function.\relax }}{37}{figure.caption.9}}
\newlabel{fig:f_ASGD}{{2.6}{37}{Examples of $f(X_i)$ as published in Ref. \cite {ASGD}. As $\omega \to 0$, $f(x)$ approaches a step function.\relax \relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{Implementation}{37}{figure.caption.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Results of Adaptive Stochastic Gradient Descent used on a two-particle quantum dot with unit oscillator frequency using $400$ cycles pr. gradient sampling and $40$ independent walkers. The right figure shows the evolution of the time-step. The left figure shows the evolution of the variational parameters $\alpha $ and $\beta $ introduced in Section \ref  {sec:trialWF} on top, and the evolution of the gradients on the bottom. The gradients are averaged to reveal the pattern underlying the noise. Dispite this averaging, it is apparent that they tend to zero, $\beta $ somewhat before $\alpha $. The step rushes to zero with a small rebound as it attempts to cross to negative values.\relax }}{38}{figure.caption.10}}
\newlabel{fig:ASGD_Ex}{{2.7}{38}{Results of Adaptive Stochastic Gradient Descent used on a two-particle quantum dot with unit oscillator frequency using $400$ cycles pr. gradient sampling and $40$ independent walkers. The right figure shows the evolution of the time-step. The left figure shows the evolution of the variational parameters $\alpha $ and $\beta $ introduced in Section \ref {sec:trialWF} on top, and the evolution of the gradients on the bottom. The gradients are averaged to reveal the pattern underlying the noise. Dispite this averaging, it is apparent that they tend to zero, $\beta $ somewhat before $\alpha $. The step rushes to zero with a small rebound as it attempts to cross to negative values.\relax \relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Chart flow of ASGD algorithm. Diffusing a walker is done as described in Figure \ref  {fig:diffFlowChart}. Updating the walkers involves recalculating any values affected by updating the minimum. The step is calculated by Eq.~(\ref  {eq:ASGD_delta_i}). In the case of QMC, the gradient is sampled by Eq.~(\ref  {eq:varParGrad}).\relax }}{39}{figure.caption.11}}
\newlabel{fig:ASGD_flow}{{2.8}{39}{Chart flow of ASGD algorithm. Diffusing a walker is done as described in Figure \ref {fig:diffFlowChart}. Updating the walkers involves recalculating any values affected by updating the minimum. The step is calculated by Eq.~(\ref {eq:ASGD_delta_i}). In the case of QMC, the gradient is sampled by Eq.~(\ref {eq:varParGrad}).\relax \relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.8}Variational Monte-Carlo}{40}{section.2.8}}
\newlabel{sec:VMC}{{2.8}{40}{Variational Monte-Carlo\relax }{section.2.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.1}Motivating the use of Diffusion Theory}{40}{subsection.2.8.1}}
\newlabel{eq:VMCrandomDistE}{{2.73}{40}{Motivating the use of Diffusion Theory\relax }{equation.2.8.73}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Chart flow of the Variational Monte-Carlo algorithm. The second step, \textit  {Diffuse Walker}, is the process described in Figure \ref  {fig:diffFlowChart}. Energies are sampled as described in Section \ref  {sec:calcExpVals}. The thermalization is set to a fixed number of cycles. \relax }}{41}{figure.caption.12}}
\newlabel{fig:VMCchart}{{2.9}{41}{Chart flow of the Variational Monte-Carlo algorithm. The second step, \textit {Diffuse Walker}, is the process described in Figure \ref {fig:diffFlowChart}. Energies are sampled as described in Section \ref {sec:calcExpVals}. The thermalization is set to a fixed number of cycles. \relax \relax }{figure.caption.12}{}}
\citation{libBorealisCode}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces Comparison of the VMC energy using different trial wave functions. The DMC energy is believed to be very close to the exact ground state. It is apparent that adding a variational parameter to the trial wave function lowers the energy substantially, however, when adding the Jastrow factor (denoted \textit  {Optimal}), described in Section \ref  {sec:ChoiceTrialWF}, the VMC energy gets very close to the ``exact'' answer. A lower energy means a better energy when dealing with variational methods. In this example, a 12-particle quantum dot with unit frequency is used.\relax }}{42}{figure.caption.13}}
\newlabel{fig:VMC_wfcomp}{{2.10}{42}{Comparison of the VMC energy using different trial wave functions. The DMC energy is believed to be very close to the exact ground state. It is apparent that adding a variational parameter to the trial wave function lowers the energy substantially, however, when adding the Jastrow factor (denoted \textit {Optimal}), described in Section \ref {sec:ChoiceTrialWF}, the VMC energy gets very close to the ``exact'' answer. A lower energy means a better energy when dealing with variational methods. In this example, a 12-particle quantum dot with unit frequency is used.\relax \relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.2}Implementation}{42}{subsection.2.8.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.8.3}Limitations}{42}{subsection.2.8.3}}
\@writefile{toc}{\contentsline {section}{\numberline {2.9}Diffusion Monte-Carlo}{43}{section.2.9}}
\newlabel{sec:DMC}{{2.9}{43}{Diffusion Monte-Carlo\relax }{section.2.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.1}Implementation}{43}{subsection.2.9.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.2}Sampling the Energy}{43}{subsection.2.9.2}}
\newlabel{eq:DMC_Ek}{{2.75}{43}{Sampling the Energy\relax }{equation.2.9.75}{}}
\citation{Hirth}
\citation{abInitioMC}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.3}Limitations}{44}{subsection.2.9.3}}
\newlabel{sec:DMClimitations}{{2.9.3}{44}{Limitations\relax }{subsection.2.9.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{Time-step errors}{44}{subsection.2.9.3}}
\@writefile{toc}{\contentsline {subsubsection}{Selecting the time-step}{44}{subsection.2.9.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Chart flow of the Diffusion Monte-Carlo algorithm. The variable \textit  {i} represents the currently moved walker. The second step, \textit  {Diffuse and Branch Walker}, is the process described in Figure \ref  {fig:diffFlowChart} in combination with the branching from Figure \ref  {fig:branching}. Energies are sampled as in Eq.~(\ref  {eq:DMC_Ek}). Thermalization is set to a fixed number of cycles.\relax }}{45}{figure.caption.14}}
\newlabel{fig:DMCchart}{{2.11}{45}{Chart flow of the Diffusion Monte-Carlo algorithm. The variable \textit {i} represents the currently moved walker. The second step, \textit {Diffuse and Branch Walker}, is the process described in Figure \ref {fig:diffFlowChart} in combination with the branching from Figure \ref {fig:branching}. Energies are sampled as in Eq.~(\ref {eq:DMC_Ek}). Thermalization is set to a fixed number of cycles.\relax \relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.9.4}Fixed node approximation}{46}{subsection.2.9.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.10}Estimating One-body Densities}{46}{section.2.10}}
\newlabel{sec:OBD}{{2.10}{46}{Estimating One-body Densities\relax }{section.2.10}{}}
\citation{abInitioMC}
\citation{leinaas}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces A one-dimensional illustration of the fixed node approximation. The dotted line represents the exact ground state $\Psi _0(x)$. The distribution of walkers after $n$ Monte-Carlo cycles is represented by $\Phi (x, n\delta \tau )$. The trial wave function $\Psi _T(x)$ shares nodes with $\Phi (x, n\delta \tau )$, making it impossible for $\Phi (x, n\delta \tau )$ to match $\Psi _0(x)$.\relax }}{47}{figure.caption.15}}
\newlabel{fig:fixxednode}{{2.12}{47}{A one-dimensional illustration of the fixed node approximation. The dotted line represents the exact ground state $\Psi _0(x)$. The distribution of walkers after $n$ Monte-Carlo cycles is represented by $\Phi (x, n\delta \tau )$. The trial wave function $\Psi _T(x)$ shares nodes with $\Phi (x, n\delta \tau )$, making it impossible for $\Phi (x, n\delta \tau )$ to match $\Psi _0(x)$.\relax \relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10.1}Estimating the Exact Ground State Density}{47}{subsection.2.10.1}}
\newlabel{eq:PureEstimRelat}{{2.84}{47}{Estimating the Exact Ground State Density\relax }{equation.2.10.84}{}}
\newlabel{eq:densityTransform}{{2.86}{48}{Estimating the Exact Ground State Density\relax }{equation.2.10.86}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.10.2}Radial Densities}{48}{subsection.2.10.2}}
\newlabel{eq:averagedRadialOBD_3D}{{2.87}{48}{Radial Densities\relax }{equation.2.10.87}{}}
\newlabel{eq:averagedRadialOBD_2D}{{2.88}{48}{Radial Densities\relax }{equation.2.10.88}{}}
\newlabel{eq:radial_OBD}{{2.89}{48}{Radial Densities\relax }{equation.2.10.89}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Two examples of radial one-body densities for VMC, DMC, and the pure density from Eq.~(\ref  {eq:densityTransform}). On the left: A 12-particle two-dimensional quantum dot with frequency $\omega =0.1$. The density diverges close to zero due to a ``$\frac  {0}{0}$'' expression (see Eq.~(\ref  {eq:radial_OBD})). On the right: Unscaled radial density for the beryllium atom, i.e.~$r_1^2\rho (\mathbf  {r}_1)$. The densities will be discussed in the result section.\relax }}{49}{figure.caption.16}}
\newlabel{fig:OBD_ex}{{2.13}{49}{Two examples of radial one-body densities for VMC, DMC, and the pure density from Eq.~(\ref {eq:densityTransform}). On the left: A 12-particle two-dimensional quantum dot with frequency $\omega =0.1$. The density diverges close to zero due to a ``$\frac {0}{0}$'' expression (see Eq.~(\ref {eq:radial_OBD})). On the right: Unscaled radial density for the beryllium atom, i.e.~$r_1^2\rho (\mathbf {r}_1)$. The densities will be discussed in the result section.\relax \relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.11}Estimating the Statistical Error}{49}{section.2.11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.11.1}The Variance and Standard Deviates}{49}{subsection.2.11.1}}
\newlabel{sec:varAndSTD}{{2.11.1}{49}{The Variance and Standard Deviates\relax }{subsection.2.11.1}{}}
\newlabel{eq:variance}{{2.90}{49}{The Variance and Standard Deviates\relax }{equation.2.11.90}{}}
\newlabel{eq:varianceZeroExact}{{2.93}{50}{The Variance and Standard Deviates\relax }{}{}}
\newlabel{eq:stdNaive}{{2.93}{50}{The Variance and Standard Deviates\relax }{equation.2.11.93}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.11.2}The Covariance and correlated samples}{50}{subsection.2.11.2}}
\newlabel{eq:covariance}{{2.94}{50}{The Covariance and correlated samples\relax }{equation.2.11.94}{}}
\newlabel{eq:trueVsNaiveSTD}{{2.95}{51}{The Covariance and correlated samples\relax }{equation.2.11.95}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.11.3}The Deviate from the Exact Mean}{51}{subsection.2.11.3}}
\newlabel{eq:meanx}{{2.97}{51}{The Deviate from the Exact Mean\relax }{equation.2.11.97}{}}
\newlabel{eq:sigma_m}{{2.98}{51}{The Deviate from the Exact Mean\relax }{equation.2.11.98}{}}
\newlabel{eq:realErrorCovariance1}{{2.99}{51}{The Deviate from the Exact Mean\relax }{equation.2.11.99}{}}
\citation{flyvbjerg:461}
\citation{morten}
\citation{flyvbjerg:461}
\newlabel{eq:realErrorCovariance2}{{2.102}{52}{The Deviate from the Exact Mean\relax }{equation.2.11.102}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.11.4}Blocking}{52}{subsection.2.11.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.14}{\ignorespaces Left hand side: Blocking result of (approximately) uncorrelated data generated from a uniform Monte-Carlo integration of $\DOTSI \intop \ilimits@ _1^2 2x\mathrm  {d}x$ resulting in $3.00003$ (exact is $3.0$). This is in excellent agreement with the magnitude of the error $\sim 9\cdot 10^{-5}$. There is no sign of a plateau, which implies fairly uncorrelated data (the span of the spread is small and apparently random). Right hand side: Blocking result of a DMC simulation of a 6-particle two-dimensional quantum dot with frequency $\omega =0.1$. The plateau is strongly present, implying correlated data. The resulting total error is $\sim 4.5\cdot 10^{-5}$.\relax }}{53}{figure.caption.17}}
\newlabel{FIG:BlockingExamples}{{2.14}{53}{Left hand side: Blocking result of (approximately) uncorrelated data generated from a uniform Monte-Carlo integration of $\int _1^2 2x\mathrm {d}x$ resulting in $3.00003$ (exact is $3.0$). This is in excellent agreement with the magnitude of the error $\sim 9\cdot 10^{-5}$. There is no sign of a plateau, which implies fairly uncorrelated data (the span of the spread is small and apparently random). Right hand side: Blocking result of a DMC simulation of a 6-particle two-dimensional quantum dot with frequency $\omega =0.1$. The plateau is strongly present, implying correlated data. The resulting total error is $\sim 4.5\cdot 10^{-5}$.\relax \relax }{figure.caption.17}{}}
\newlabel{eq:blockingError}{{2.106}{53}{Blocking\relax }{equation.2.11.105}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.11.5}Variance Estimators}{53}{subsection.2.11.5}}
\newlabel{eq:varBias}{{2.107}{54}{Variance Estimators\relax }{equation.2.11.107}{}}
\newlabel{eq:varUnbias}{{2.108}{54}{Variance Estimators\relax }{equation.2.11.108}{}}
\@writefile{toc}{\contentsline {part}{II\hspace  {1em}Results}{55}{part.2}}
\bibstyle{IEEEtran}
\bibdata{../bibtex/bibtex.bib}
\bibcite{verdensBesteArtikkel}{1}
\bibcite{Hirth}{2}
\bibcite{H_He_exact}{3}
\bibcite{ExactMolecules}{4}
\bibcite{AtomsExact}{5}
\bibcite{KryptonExact}{6}
\bibcite{forcesQMC}{7}
\bibcite{Olsen}{8}
\bibcite{libBorealisCode}{9}
\bibcite{MD1}{10}
\bibcite{MD2}{11}
\bibcite{griffiths}{12}
\bibcite{Shavitt}{13}
\bibcite{Sigve}{14}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{59}{section*.18}}
\bibcite{QMCDIFF}{15}
\bibcite{abInitioMC}{16}
\bibcite{Gardiner:2004bk}{17}
\bibcite{risken1989fpe}{18}
\bibcite{langevin}{19}
\bibcite{robertcasella}{20}
\bibcite{morten}{21}
\bibcite{Sakurai:94}{22}
\bibcite{larseivind}{23}
\bibcite{QMCPHD2008}{24}
\bibcite{UmrigarMolecules}{25}
\bibcite{golub1996matrix}{26}
\bibcite{ASGD_MB}{27}
\bibcite{ASGD}{28}
\bibcite{leinaas}{29}
\bibcite{flyvbjerg:461}{30}
